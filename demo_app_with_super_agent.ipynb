{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "54uw_8McPd8d",
      "metadata": {
        "id": "54uw_8McPd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting squidpy\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4a/d9/419c241e27ec311793bdb2980d7261f5383eadaed56354161865a65b102b/squidpy-1.6.5-py3-none-any.whl (161 kB)\n",
            "Collecting scanpy\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/32/e9/c1d43543da87cd27e8e2a74db85cf0b6c5cff2d5f04a86bd584d2fbc2bb0/scanpy-1.11.5-py3-none-any.whl (2.1 MB)\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "     ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
            "     ------------------------ --------------- 1.3/2.1 MB 3.2 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 1.8/2.1 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.1/2.1 MB 3.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (3.12.14)\n",
            "Collecting anndata>=0.9 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0a/4b/ab615fea52e34579d5c6c7dba86b4f9d7f3cdb6a170b348ec49f34cf4355/anndata-0.11.4-py3-none-any.whl (144 kB)\n",
            "Collecting cycler>=0.11.0 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting dask-image>=0.5.0 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/4b/817da308fa1170da07ef01259585887a3bbb6ab80700b3e61ce4967301ec/dask_image-2025.11.0-py3-none-any.whl (61 kB)\n",
            "Collecting dask<=2024.11.2,>=2021.02.0 (from dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2a/72/33ff765a07913cb5061baa94718f3a17003aa29adc89642a68c295d47582/dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
            "Collecting docrep>=0.3.1 (from squidpy)\n",
            "  Using cached docrep-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: fsspec>=2021.11.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (2025.7.0)\n",
            "Collecting matplotlib-scalebar>=0.8.0 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a8/c0/2dfab7b319dabe23f5a7b515a797c74b501d15c72e7a03837cf0cf779b9e/matplotlib_scalebar-0.9.0-py3-none-any.whl (16 kB)\n",
            "Collecting matplotlib>=3.3 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/65/7d/954b3067120456f472cce8fdcacaf4a5fcd522478db0c37bb243c7cb59dd/matplotlib-3.10.7-cp310-cp310-win_amd64.whl (8.1 MB)\n",
            "     ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 0.8/8.1 MB 3.7 MB/s eta 0:00:02\n",
            "     ------- -------------------------------- 1.6/8.1 MB 4.0 MB/s eta 0:00:02\n",
            "     ------------ --------------------------- 2.6/8.1 MB 4.4 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 3.4/8.1 MB 4.2 MB/s eta 0:00:02\n",
            "     --------------------- ------------------ 4.5/8.1 MB 4.5 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 5.5/8.1 MB 4.4 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 6.6/8.1 MB 4.5 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 7.1/8.1 MB 4.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 8.1/8.1 MB 4.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: networkx>=2.6.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (3.4.2)\n",
            "Collecting numba>=0.56.4 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/86/94/20ae0ff78612c4697eaf942a639db01dd4e2d90f634ac41fa3e015c961fc/numba-0.62.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
            "     ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "     ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------- ----------------- 1.6/2.7 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 2.4/2.7 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.7/2.7 MB 4.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.23.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (2.2.6)\n",
            "Collecting omnipath>=1.0.7 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d7/ba/704f9e56ae80ef66cf0534e23dac22ada34845f86b5e5b8b3294649d96b6/omnipath-1.0.12-py3-none-any.whl (51 kB)\n",
            "Collecting pandas>=2.1.0 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/85/72/530900610650f54a35a19476eca5104f38555afccda1aa11a92ee14cb21d/pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
            "     ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.8/11.3 MB 5.6 MB/s eta 0:00:02\n",
            "     ----- ---------------------------------- 1.6/11.3 MB 4.7 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 2.6/11.3 MB 4.4 MB/s eta 0:00:02\n",
            "     ----------- ---------------------------- 3.1/11.3 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------- -------------------------- 3.9/11.3 MB 3.8 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 4.5/11.3 MB 3.6 MB/s eta 0:00:02\n",
            "     ------------------ --------------------- 5.2/11.3 MB 3.6 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 5.8/11.3 MB 3.5 MB/s eta 0:00:02\n",
            "     ---------------------- ----------------- 6.3/11.3 MB 3.5 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 6.8/11.3 MB 3.4 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 7.3/11.3 MB 3.2 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 7.6/11.3 MB 3.1 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 8.1/11.3 MB 3.0 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 8.4/11.3 MB 2.9 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 8.9/11.3 MB 2.8 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 9.2/11.3 MB 2.8 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 9.7/11.3 MB 2.7 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 10.2/11.3 MB 2.7 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 10.7/11.3 MB 2.7 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 11.0/11.3 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 11.3/11.3 MB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow>=8.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (11.3.0)\n",
            "Collecting scikit-image>=0.20 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5f/ee/c53a009e3997dda9d285402f19226fbd17b5b3cb215da391c4ed084a1424/scikit_image-0.25.2-cp310-cp310-win_amd64.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.8/12.8 MB 2.1 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 1.0/12.8 MB 2.0 MB/s eta 0:00:06\n",
            "     ---- ----------------------------------- 1.6/12.8 MB 2.0 MB/s eta 0:00:06\n",
            "     ------ --------------------------------- 2.1/12.8 MB 2.1 MB/s eta 0:00:06\n",
            "     -------- ------------------------------- 2.6/12.8 MB 2.1 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 2.9/12.8 MB 2.0 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 3.1/12.8 MB 2.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 3.7/12.8 MB 1.9 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 3.9/12.8 MB 1.9 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 4.5/12.8 MB 2.0 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 2.0 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 5.2/12.8 MB 1.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 5.5/12.8 MB 1.9 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 6.0/12.8 MB 2.0 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 6.3/12.8 MB 1.9 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 6.6/12.8 MB 1.9 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 6.8/12.8 MB 1.8 MB/s eta 0:00:04\n",
            "     ---------------------- ----------------- 7.3/12.8 MB 1.8 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 8.1/12.8 MB 1.9 MB/s eta 0:00:03\n",
            "     ---------------------------- ----------- 9.2/12.8 MB 2.1 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 10.0/12.8 MB 2.2 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 11.0/12.8 MB 2.3 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.6/12.8 MB 2.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 2.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (1.7.1)\n",
            "Collecting spatialdata>=0.2.5 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8b/45/f16a66337b05f6c4829d0e9bdc0c6f876e5a193a1cdc1c88f7dee5a3762a/spatialdata-0.5.0-py3-none-any.whl (185 kB)\n",
            "Collecting statsmodels>=0.12.0 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d1/6f/6de51f1077b7cef34611f1d6721392ea170153251b4d977efcf6d100f779/statsmodels-0.14.5-cp310-cp310-win_amd64.whl (9.6 MB)\n",
            "Collecting tifffile!=2022.4.22 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/06/bd0a6097da704a7a7c34a94cfd771c3ea3c2f405dd214e790d22c93f6be1/tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
            "Requirement already satisfied: tqdm>=4.50.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from squidpy) (4.67.1)\n",
            "Collecting validators>=0.18.2 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fa/6e/3e955517e22cbdd565f2f8b2e73d52528b14b8bcfdb04f62466b071de847/validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "Collecting xarray>=2024.10.0 (from squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/82/8a/6b50c1dd2260d407c1a499d47cf829f59f07007e0dcebafdabb24d1d26a5/xarray-2025.6.1-py3-none-any.whl (1.3 MB)\n",
            "Collecting zarr<3.0.0,>=2.6.1 (from squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/c9/142095e654c2b97133ff71df60979422717b29738b08bc8a1709a5d5e0d0/zarr-2.18.3-py3-none-any.whl (210 kB)\n",
            "Requirement already satisfied: click>=8.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (8.2.1)\n",
            "Collecting cloudpickle>=3.0.0 (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/88/39/799be3f2f0f38cc727ee3b4f1445fe6d5e4133064ec2e4115069418a5bb6/cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (25.0)\n",
            "Collecting partd>=1.4.0 (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/e7/40fb618334dcdf7c5a316c0e7343c5cd82d3d866edc100d98e29bc945ecd/partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (6.0.2)\n",
            "Collecting toolz>=0.10.0 (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fb/12/5911ae3eeec47800503a238d971e51722ccea5feb8569b735184d5fcdbc0/toolz-1.1.0-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (8.7.0)\n",
            "Collecting asciitree (from zarr<3.0.0,>=2.6.1->squidpy)\n",
            "  Using cached asciitree-0.3.3-py3-none-any.whl\n",
            "Collecting numcodecs>=0.10.0 (from zarr<3.0.0,>=2.6.1->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/90/299952e1477954ec4f92813fa03e743945e3ff711bb4f6c9aace431cb3da/numcodecs-0.13.1-cp310-cp310-win_amd64.whl (828 kB)\n",
            "     ---------------------------------------- 0.0/828.6 kB ? eta -:--:--\n",
            "     ------------------------ ------------- 524.3/828.6 kB 2.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- 828.6/828.6 kB 2.1 MB/s eta 0:00:00\n",
            "Collecting fasteners (from zarr<3.0.0,>=2.6.1->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/51/ac/e5d886f892666d2d1e5cb8c1a41146e1d79ae8896477b1153a21711d3b44/fasteners-0.20-py3-none-any.whl (18 kB)\n",
            "Collecting h5py>=3.7.0 (from scanpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/28/dc08de359c2f43a67baa529cb70d7f9599848750031975eed92d6ae78e1d/h5py-3.15.1-cp310-cp310-win_amd64.whl (2.9 MB)\n",
            "     ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
            "     ------- -------------------------------- 0.5/2.9 MB 1.2 MB/s eta 0:00:02\n",
            "     ---------- ----------------------------- 0.8/2.9 MB 1.2 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 1.0/2.9 MB 1.2 MB/s eta 0:00:02\n",
            "     ------------------ --------------------- 1.3/2.9 MB 1.2 MB/s eta 0:00:02\n",
            "     --------------------- ------------------ 1.6/2.9 MB 1.2 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 1.8/2.9 MB 1.3 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 2.1/2.9 MB 1.2 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 2.4/2.9 MB 1.3 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 2.6/2.9 MB 1.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.9/2.9 MB 1.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy) (1.5.1)\n",
            "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/41/5b/058db09c45ba58a7321bdf2294cae651b37d6fec68117265af90cde043b0/legacy_api_wrap-1.5-py3-none-any.whl (10 kB)\n",
            "Collecting natsort (from scanpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ef/82/7a9d0550484a62c6da82858ee9419f3dd1ccc9aa1c26a1e43da3ecd20b0d/natsort-8.4.0-py3-none-any.whl (38 kB)\n",
            "Collecting patsy!=1.0.0 (from scanpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/70/ba4b949bdc0490ab78d545459acd7702b211dfccf7eb89bbc1060f52818d/patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
            "Collecting pynndescent>=0.5.13 (from scanpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d2/53/d23a97e0a2c690d40b165d1062e2c4ccc796be458a1ce59f6ba030434663/pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: scipy>=1.8.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy) (1.15.3)\n",
            "Collecting seaborn>=0.13.2 (from scanpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9d/b7/7d4c95c7b8525dabea23c548a1bb068d7a61635d544e8c92c51e784dad63/session_info2-0.2.3-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy) (4.14.1)\n",
            "Collecting umap-learn>=0.5.6 (from scanpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6b/b1/c24deeda9baf1fd491aaad941ed89e0fed6c583a117fd7b79e0a33a1e6c0/umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from aiohttp>=3.8.1->squidpy) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.8.1->squidpy) (3.10)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.9->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e0/b1/0542e0cab6f49f151a2d7a42400f84f706fc0b64e85dc1f56708b2e9fd37/array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: exceptiongroup in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.9->squidpy) (1.3.0)\n",
            "Requirement already satisfied: colorama in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from click>=8.1->dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (0.4.6)\n",
            "Collecting pims>=0.4.1 (from dask-image>=0.5.0->squidpy)\n",
            "  Using cached pims-0.7-py3-none-any.whl\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a9/99/60c73ccb5a272ff396bc766bfa3c9caa71484424983f0334070263a16581/dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c5/a4/c7c8e2a895eba9ce41bf811b2b6755c227a489b687d1a52521350ae37436/dask_expr-1.1.20-py3-none-any.whl (245 kB)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e9/57/e7996529256b13009fa8f4c34d1d7229755cc7d2b054aa43edb6ca655578/dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
            "Collecting pyarrow>=14.0.1 (from dask-expr<1.2,>=1.1->dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/80/07/fea6578112c8c60ffde55883a571e4c4c6bc7049f119d6b09333b5cc6f73/pyarrow-22.0.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
            "     ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.3/28.1 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.5/28.1 MB 1.4 MB/s eta 0:00:20\n",
            "     - -------------------------------------- 0.8/28.1 MB 1.5 MB/s eta 0:00:18\n",
            "     - -------------------------------------- 1.3/28.1 MB 1.7 MB/s eta 0:00:16\n",
            "     -- ------------------------------------- 1.8/28.1 MB 2.0 MB/s eta 0:00:14\n",
            "     ---- ----------------------------------- 2.9/28.1 MB 2.5 MB/s eta 0:00:11\n",
            "     ----- ---------------------------------- 3.7/28.1 MB 2.8 MB/s eta 0:00:09\n",
            "     ------ --------------------------------- 4.7/28.1 MB 3.1 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 5.5/28.1 MB 3.2 MB/s eta 0:00:08\n",
            "     --------- ------------------------------ 6.6/28.1 MB 3.4 MB/s eta 0:00:07\n",
            "     ---------- ----------------------------- 7.3/28.1 MB 3.4 MB/s eta 0:00:07\n",
            "     ----------- ---------------------------- 8.4/28.1 MB 3.5 MB/s eta 0:00:06\n",
            "     ------------- -------------------------- 9.2/28.1 MB 3.6 MB/s eta 0:00:06\n",
            "     -------------- ------------------------- 10.0/28.1 MB 3.6 MB/s eta 0:00:06\n",
            "     --------------- ------------------------ 11.0/28.1 MB 3.6 MB/s eta 0:00:05\n",
            "     ---------------- ----------------------- 11.5/28.1 MB 3.6 MB/s eta 0:00:05\n",
            "     ----------------- ---------------------- 12.6/28.1 MB 3.7 MB/s eta 0:00:05\n",
            "     ------------------- -------------------- 13.4/28.1 MB 3.7 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 14.2/28.1 MB 3.7 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 14.7/28.1 MB 3.6 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 15.2/28.1 MB 3.6 MB/s eta 0:00:04\n",
            "     ---------------------- ----------------- 15.7/28.1 MB 3.5 MB/s eta 0:00:04\n",
            "     ---------------------- ----------------- 16.0/28.1 MB 3.5 MB/s eta 0:00:04\n",
            "     ----------------------- ---------------- 16.3/28.1 MB 3.4 MB/s eta 0:00:04\n",
            "     ----------------------- ---------------- 16.8/28.1 MB 3.3 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 17.0/28.1 MB 3.2 MB/s eta 0:00:04\n",
            "     ------------------------ --------------- 17.3/28.1 MB 3.2 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 17.8/28.1 MB 3.1 MB/s eta 0:00:04\n",
            "     ------------------------- -------------- 18.1/28.1 MB 3.1 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 18.4/28.1 MB 3.0 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 18.6/28.1 MB 3.0 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 18.9/28.1 MB 2.9 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 19.1/28.1 MB 2.8 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 19.1/28.1 MB 2.8 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 19.4/28.1 MB 2.7 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 19.7/28.1 MB 2.7 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 19.9/28.1 MB 2.6 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 20.2/28.1 MB 2.6 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 20.4/28.1 MB 2.5 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 20.7/28.1 MB 2.5 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 21.0/28.1 MB 2.5 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 21.0/28.1 MB 2.5 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 21.2/28.1 MB 2.4 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 21.5/28.1 MB 2.4 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 21.8/28.1 MB 2.3 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 22.0/28.1 MB 2.3 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 22.0/28.1 MB 2.3 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 22.3/28.1 MB 2.2 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 22.5/28.1 MB 2.2 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 23.1/28.1 MB 2.2 MB/s eta 0:00:03\n",
            "     --------------------------------- ------ 23.6/28.1 MB 2.2 MB/s eta 0:00:03\n",
            "     ---------------------------------- ----- 24.1/28.1 MB 2.2 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 24.6/28.1 MB 2.2 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 25.2/28.1 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 25.7/28.1 MB 2.2 MB/s eta 0:00:02\n",
            "     ------------------------------------- -- 26.2/28.1 MB 2.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 26.7/28.1 MB 2.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 27.3/28.1 MB 2.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  27.8/28.1 MB 2.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 28.1/28.1 MB 2.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from docrep>=0.3.1->squidpy) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from importlib-metadata>=4.13.0->dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy) (3.23.0)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.3->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/54/ec/5162b8582f2c994721018d0c9ece9dc6ff769d298a8ac6b6a652c307e7df/contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.3->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/84/62a19e2bd56f0e9fb347486a5b26376bade4bf6bbba64dda2c103bd08c94/fonttools-4.60.1-cp310-cp310-win_amd64.whl (2.3 MB)\n",
            "     ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "     --------- ------------------------------ 0.5/2.3 MB 4.2 MB/s eta 0:00:01\n",
            "     --------------------------- ------------ 1.6/2.3 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.3/2.3 MB 4.3 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a2/55/c2898d84ca440852e560ca9f2a0d28e6e931ac0849b896d77231929900e7/kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib>=3.3->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/10/5e/1aa9a93198c6b64513c9d7752de7422c06402de6600a8767da1524f9570b/pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.3->squidpy) (2.9.0.post0)\n",
            "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.56.4->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/c0/233468e96ed287b953239c3b24b1d69df47c6ba9262bfdca98eda7e83a04/llvmlite-0.45.1-cp310-cp310-win_amd64.whl (38.1 MB)\n",
            "     ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.8/38.1 MB 4.8 MB/s eta 0:00:08\n",
            "     - -------------------------------------- 1.6/38.1 MB 4.2 MB/s eta 0:00:09\n",
            "     -- ------------------------------------- 2.6/38.1 MB 4.2 MB/s eta 0:00:09\n",
            "     --- ------------------------------------ 3.1/38.1 MB 4.3 MB/s eta 0:00:09\n",
            "     ---- ----------------------------------- 4.2/38.1 MB 4.1 MB/s eta 0:00:09\n",
            "     ----- ---------------------------------- 5.2/38.1 MB 4.1 MB/s eta 0:00:08\n",
            "     ------ --------------------------------- 6.0/38.1 MB 4.2 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 6.8/38.1 MB 4.1 MB/s eta 0:00:08\n",
            "     ------- -------------------------------- 7.3/38.1 MB 4.0 MB/s eta 0:00:08\n",
            "     -------- ------------------------------- 8.1/38.1 MB 3.9 MB/s eta 0:00:08\n",
            "     --------- ------------------------------ 8.9/38.1 MB 3.9 MB/s eta 0:00:08\n",
            "     ---------- ----------------------------- 9.7/38.1 MB 3.9 MB/s eta 0:00:08\n",
            "     ---------- ----------------------------- 10.2/38.1 MB 3.9 MB/s eta 0:00:08\n",
            "     ----------- ---------------------------- 10.7/38.1 MB 3.8 MB/s eta 0:00:08\n",
            "     ----------- ---------------------------- 11.3/38.1 MB 3.6 MB/s eta 0:00:08\n",
            "     ------------ --------------------------- 11.8/38.1 MB 3.5 MB/s eta 0:00:08\n",
            "     ------------ --------------------------- 12.1/38.1 MB 3.4 MB/s eta 0:00:08\n",
            "     ------------ --------------------------- 12.3/38.1 MB 3.3 MB/s eta 0:00:08\n",
            "     ------------- -------------------------- 12.6/38.1 MB 3.2 MB/s eta 0:00:08\n",
            "     ------------- -------------------------- 13.1/38.1 MB 3.1 MB/s eta 0:00:09\n",
            "     -------------- ------------------------- 13.4/38.1 MB 3.1 MB/s eta 0:00:09\n",
            "     -------------- ------------------------- 13.9/38.1 MB 3.0 MB/s eta 0:00:09\n",
            "     --------------- ------------------------ 14.4/38.1 MB 3.0 MB/s eta 0:00:08\n",
            "     ---------------- ----------------------- 15.5/38.1 MB 3.1 MB/s eta 0:00:08\n",
            "     ----------------- ---------------------- 16.3/38.1 MB 3.1 MB/s eta 0:00:08\n",
            "     ----------------- ---------------------- 17.0/38.1 MB 3.1 MB/s eta 0:00:07\n",
            "     ------------------ --------------------- 18.1/38.1 MB 3.2 MB/s eta 0:00:07\n",
            "     -------------------- ------------------- 19.1/38.1 MB 3.2 MB/s eta 0:00:06\n",
            "     -------------------- ------------------- 19.9/38.1 MB 3.3 MB/s eta 0:00:06\n",
            "     --------------------- ------------------ 20.7/38.1 MB 3.3 MB/s eta 0:00:06\n",
            "     ---------------------- ----------------- 21.8/38.1 MB 3.3 MB/s eta 0:00:05\n",
            "     ----------------------- ---------------- 22.8/38.1 MB 3.4 MB/s eta 0:00:05\n",
            "     ------------------------- -------------- 23.9/38.1 MB 3.4 MB/s eta 0:00:05\n",
            "     ------------------------- -------------- 24.6/38.1 MB 3.4 MB/s eta 0:00:04\n",
            "     -------------------------- ------------- 25.7/38.1 MB 3.5 MB/s eta 0:00:04\n",
            "     --------------------------- ------------ 26.2/38.1 MB 3.5 MB/s eta 0:00:04\n",
            "     ---------------------------- ----------- 27.3/38.1 MB 3.5 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 28.0/38.1 MB 3.5 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 28.8/38.1 MB 3.5 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 29.6/38.1 MB 3.5 MB/s eta 0:00:03\n",
            "     -------------------------------- ------- 30.7/38.1 MB 3.6 MB/s eta 0:00:03\n",
            "     --------------------------------- ------ 31.7/38.1 MB 3.6 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 32.5/38.1 MB 3.6 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 33.6/38.1 MB 3.6 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 34.3/38.1 MB 3.6 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 35.1/38.1 MB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 35.9/38.1 MB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 35.9/38.1 MB 3.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 36.2/38.1 MB 3.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  37.2/38.1 MB 3.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  38.0/38.1 MB 3.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 38.1/38.1 MB 3.5 MB/s eta 0:00:00\n",
            "Collecting inflect>=4.1.0 (from omnipath>=1.0.7->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8a/eb/427ed2b20a38a4ee29f24dbe4ae2dafab198674fe9a85e3d6adf9e5f5f41/inflect-7.5.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: requests>=2.24.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from omnipath>=1.0.7->squidpy) (2.32.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from omnipath>=1.0.7->squidpy) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.12.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from omnipath>=1.0.7->squidpy) (2.0.1)\n",
            "Collecting more_itertools>=8.5.0 (from inflect>=4.1.0->omnipath>=1.0.7->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/8e/469e5a4a2f5855992e425f3cb33804cc07bf18d48f2db061aec61ce50270/more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=4.1.0->omnipath>=1.0.7->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1b/a9/e3aee762739c1d7528da1c3e06d518503f8b6c439c35549b53735ba52ead/typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=2.1.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.1.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Collecting locket (from partd>=1.4.0->dask<=2024.11.2,>=2021.02.0->dask[array]<=2024.11.2,>=2021.02.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/db/bc/83e112abc66cd466c6b83f99118035867cecd41802f8d044638aa78a106e/locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting imageio (from pims>=0.4.1->dask-image>=0.5.0->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fb/fe/301e0936b79bcab4cacc7548bf2853fc28dced0a578bab1f7ef53c9aa75b/imageio-2.37.2-py3-none-any.whl (317 kB)\n",
            "Collecting slicerator>=0.9.8 (from pims>=0.4.1->dask-image>=0.5.0->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e8/ae/fa6cd331b364ad2bbc31652d025f5747d89cbb75576733dfdf8efe3e4d62/slicerator-1.1.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.24.0->omnipath>=1.0.7->squidpy) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.24.0->omnipath>=1.0.7->squidpy) (2025.7.14)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image>=0.20->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scikit-learn>=0.24.0->squidpy) (3.6.0)\n",
            "Collecting datashader (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/28/0e/b11ad5fd77e3dd0baad9cac3184315be7654ae401e3b0b0c324503f23d96/datashader-0.18.2-py3-none-any.whl (18.3 MB)\n",
            "Collecting geopandas>=0.14 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/0b/70/d5cd0696eff08e62fdbdebe5b46527facb4e7220eabe0ac6225efab50168/geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
            "Collecting multiscale-spatial-image>=2.0.3 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/01/a7/fec56dbac873a18930b2127d400794a91dd53898bff811aa4802ddbbfac9/multiscale_spatial_image-2.0.3-py3-none-any.whl (29 kB)\n",
            "Collecting ome-zarr>=0.8.4 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4f/21/59baa90924b815b70f88045f0b206b7eab0b68b461c0192692486b516ab7/ome_zarr-0.12.2-py3-none-any.whl (41 kB)\n",
            "Collecting pooch (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a8/87/77cc11c7a9ea9fd05503def69e3d18605852cd0d4b0d3b8f15bbeb3ef1d1/pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Requirement already satisfied: rich in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from spatialdata>=0.2.5->squidpy) (14.0.0)\n",
            "Requirement already satisfied: setuptools in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from spatialdata>=0.2.5->squidpy) (80.9.0)\n",
            "Requirement already satisfied: shapely>=2.0.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from spatialdata>=0.2.5->squidpy) (2.1.1)\n",
            "Collecting spatial-image>=1.2.3 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d0/5a/8ef888a4f56fa2ea5c10a7d6ff02286f503a93ea298bcaa9f51a41a20df8/spatial_image-1.2.3-py3-none-any.whl (8.7 kB)\n",
            "Collecting xarray-schema (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a9/6d/f585a27b380ee987619b5617c0ca672a71a4345b67cfedbb6299750ce845/xarray_schema-0.0.3-py3-none-any.whl (10 kB)\n",
            "Collecting xarray-spatial>=0.3.5 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f3/72/8cc5d33d86260e030cd703a5b5021656d1c49066cad710825f0b23428ef6/xarray_spatial-0.4.0-py3-none-any.whl (2.0 MB)\n",
            "Collecting pyogrio>=0.7.2 (from geopandas>=0.14->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f5/15/fb6ed944f76aff08a98618f1ff184ad4dc3eb026b4a74d7e5cc01125be43/pyogrio-0.11.1-cp310-cp310-win_amd64.whl (19.2 MB)\n",
            "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.8/19.2 MB 5.6 MB/s eta 0:00:04\n",
            "     --- ------------------------------------ 1.8/19.2 MB 4.8 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 2.9/19.2 MB 4.7 MB/s eta 0:00:04\n",
            "     ------- -------------------------------- 3.4/19.2 MB 4.5 MB/s eta 0:00:04\n",
            "     --------- ------------------------------ 4.5/19.2 MB 4.3 MB/s eta 0:00:04\n",
            "     ---------- ----------------------------- 5.2/19.2 MB 4.3 MB/s eta 0:00:04\n",
            "     ------------ --------------------------- 6.0/19.2 MB 4.2 MB/s eta 0:00:04\n",
            "     -------------- ------------------------- 7.1/19.2 MB 4.2 MB/s eta 0:00:03\n",
            "     ---------------- ----------------------- 7.9/19.2 MB 4.2 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 8.7/19.2 MB 4.1 MB/s eta 0:00:03\n",
            "     ------------------- -------------------- 9.2/19.2 MB 4.0 MB/s eta 0:00:03\n",
            "     -------------------- ------------------- 10.0/19.2 MB 3.9 MB/s eta 0:00:03\n",
            "     ---------------------- ----------------- 10.7/19.2 MB 3.9 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 11.8/19.2 MB 4.0 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 12.6/19.2 MB 4.0 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 13.6/19.2 MB 4.1 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 14.4/19.2 MB 4.1 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 15.2/19.2 MB 4.1 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 16.3/19.2 MB 4.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 17.3/19.2 MB 4.1 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 18.1/19.2 MB 4.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------  18.9/19.2 MB 4.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 19.2/19.2 MB 4.1 MB/s eta 0:00:00\n",
            "Collecting pyproj>=3.5.0 (from geopandas>=0.14->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/09/6a/ca145467fd2e5b21e3d5b8c2b9645dcfb3b68f08b62417699a1f5689008e/pyproj-3.7.1-cp310-cp310-win_amd64.whl (6.3 MB)\n",
            "     ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 0.8/6.3 MB 3.7 MB/s eta 0:00:02\n",
            "     ----------- ---------------------------- 1.8/6.3 MB 4.2 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 2.6/6.3 MB 4.4 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 3.4/6.3 MB 4.4 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 4.5/6.3 MB 4.2 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 5.2/6.3 MB 4.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 6.0/6.3 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 6.3/6.3 MB 4.2 MB/s eta 0:00:00\n",
            "Collecting xarray-dataclass>=3.0.0 (from multiscale-spatial-image>=2.0.3->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/ea/bc1de04d06b7c59fc3ff647a11fa248bf80af5a6227647a31c6250c32ce6/xarray_dataclass-3.0.0-py3-none-any.whl (16 kB)\n",
            "INFO: pip is looking at multiple versions of ome-zarr to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ome-zarr>=0.8.4 (from spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/16/10/0fbd9c7b279977e75f894a383fd906d772fde2d8c565c3dedcbdb3430ce5/ome_zarr-0.12.1-py3-none-any.whl (41 kB)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/70/86/3609b8c4deee569cd2d8b9c0a60ab37443a91ec6458212d3b18774b52447/ome_zarr-0.12.0-py3-none-any.whl (41 kB)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/24/c8/35ac60b20eccccf84638a872c3b4ebefad46b20f87540ca17a37908b1db6/ome_zarr-0.11.1-py3-none-any.whl (40 kB)\n",
            "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2d/fc/56cba14af8ad8fd020c85b6e44328520ac55939bb1f9d01444ad470504cb/s3fs-2025.10.0-py3-none-any.whl (30 kB)\n",
            "Collecting colorcet (from datashader->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c6/c6/9963d588cc3d75d766c819e0377a168ef83cf3316a92769971527a1ad1de/colorcet-3.1.0-py3-none-any.whl (260 kB)\n",
            "Collecting multipledispatch (from datashader->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/51/c0/00c9809d8b9346eb238a6bbd5f83e846a4ce4503da94a4c08cb7284c325b/multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting param (from datashader->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/dd/94/3de1f6cbaff0133a4135d9eea4dba288f0843b9925e2c1451281053f8c02/param-2.3.0-py3-none-any.whl (139 kB)\n",
            "Collecting pyct (from datashader->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8c/b2/23f4032cd1c9744aa8e9ecda43cd4d755fcb209f7f40fae035248f31a679/pyct-0.6.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pooch->spatialdata>=0.2.5->squidpy) (4.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from rich->spatialdata>=0.2.5->squidpy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from rich->spatialdata>=0.2.5->squidpy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->spatialdata>=0.2.5->squidpy) (0.1.2)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8e/ad/a2f3964aa37da5a4c94c1e5f3934d6ac1333f991f675fcf08a618397a413/aiobotocore-2.25.2-py3-none-any.whl (86 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs (from fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/37/b3/ca7d58ca25b1bb6df57e6cbd0ca8d6437a4b9ce1cd35adc8a6b2949c113b/s3fs-2025.9.0-py3-none-any.whl (30 kB)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ff/c7/30d13b7fd4f866ca3f30e9a6e7ae038f0c45226f6e26b3cc98d6d197f93b/s3fs-2025.7.0-py3-none-any.whl (30 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/a1/510b0a7fadc6f43a6ce50152e69dbd86415240835868bb0bd9b5b88b1e06/aioitertools-0.13.0-py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.40.71,>=1.40.46 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/55/d2/507fd0ee4dd574d2bdbdeac5df83f39d2cae1ffe97d4622cca6f6bab39f1/botocore-1.40.70-py3-none-any.whl (14.1 MB)\n",
            "     ---------------------------------------- 0.0/14.1 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.8/14.1 MB 4.2 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 1.8/14.1 MB 4.4 MB/s eta 0:00:03\n",
            "     ------- -------------------------------- 2.6/14.1 MB 4.2 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 3.4/14.1 MB 4.0 MB/s eta 0:00:03\n",
            "     ----------- ---------------------------- 4.2/14.1 MB 4.3 MB/s eta 0:00:03\n",
            "     -------------- ------------------------- 5.2/14.1 MB 4.2 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 6.3/14.1 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------------- -------------------- 6.8/14.1 MB 4.2 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 7.3/14.1 MB 4.0 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 8.1/14.1 MB 3.8 MB/s eta 0:00:02\n",
            "     ------------------------- -------------- 8.9/14.1 MB 3.8 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 9.7/14.1 MB 3.8 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 10.7/14.1 MB 3.9 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 11.8/14.1 MB 4.0 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 12.6/14.1 MB 4.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 13.4/14.1 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 14.1/14.1 MB 4.0 MB/s eta 0:00:00\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[s3]!=2021.07.0,!=2023.9.0,>=0.8->ome-zarr>=0.8.4->spatialdata>=0.2.5->squidpy)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting wrapt>=1.12.0 (from omnipath>=1.0.7->squidpy)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/90/ee61d36862340ad7e9d15a02529df6b948676b9a5829fd5e16640156627d/wrapt-1.17.3-cp310-cp310-win_amd64.whl (38 kB)\n",
            "Installing collected packages: slicerator, pytz, multipledispatch, asciitree, wrapt, validators, tzdata, typeguard, toolz, tifffile, session-info2, pyproj, pyparsing, pyogrio, pyarrow, patsy, param, numcodecs, natsort, more_itertools, locket, llvmlite, legacy-api-wrap, lazy-loader, kiwisolver, jmespath, imageio, h5py, fonttools, fasteners, docrep, cycler, contourpy, colorcet, cloudpickle, array-api-compat, aioitertools, zarr, scikit-image, pyct, pooch, pims, partd, pandas, numba, matplotlib, inflect, botocore, xarray, statsmodels, seaborn, pynndescent, omnipath, matplotlib-scalebar, geopandas, dask, anndata, xarray-schema, xarray-dataclass, umap-learn, datashader, dask-expr, aiobotocore, xarray-spatial, spatial-image, scanpy, s3fs, multiscale-spatial-image, dask-image, ome-zarr, spatialdata, squidpy\n",
            "\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "    ---------------------------------------  1/72 [pytz]\n",
            "   - --------------------------------------  2/72 [multipledispatch]\n",
            "   - --------------------------------------  3/72 [asciitree]\n",
            "  Attempting uninstall: wrapt\n",
            "   - --------------------------------------  3/72 [asciitree]\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "   - --------------------------------------  3/72 [asciitree]\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "   - --------------------------------------  3/72 [asciitree]\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "   - --------------------------------------  3/72 [asciitree]\n",
            "   -- -------------------------------------  4/72 [wrapt]\n",
            "   -- -------------------------------------  5/72 [validators]\n",
            "   -- -------------------------------------  5/72 [validators]\n",
            "   -- -------------------------------------  5/72 [validators]\n",
            "   -- -------------------------------------  5/72 [validators]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  6/72 [tzdata]\n",
            "   --- ------------------------------------  7/72 [typeguard]\n",
            "   ---- -----------------------------------  8/72 [toolz]\n",
            "   ---- -----------------------------------  8/72 [toolz]\n",
            "   ---- -----------------------------------  8/72 [toolz]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ----------------------------------  9/72 [tifffile]\n",
            "   ----- ---------------------------------- 10/72 [session-info2]\n",
            "   ------ --------------------------------- 11/72 [pyproj]\n",
            "   ------ --------------------------------- 11/72 [pyproj]\n",
            "   ------ --------------------------------- 11/72 [pyproj]\n",
            "   ------ --------------------------------- 12/72 [pyparsing]\n",
            "   ------ --------------------------------- 12/72 [pyparsing]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 13/72 [pyogrio]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   ------- -------------------------------- 14/72 [pyarrow]\n",
            "   -------- ------------------------------- 15/72 [patsy]\n",
            "   -------- ------------------------------- 15/72 [patsy]\n",
            "   -------- ------------------------------- 15/72 [patsy]\n",
            "   -------- ------------------------------- 16/72 [param]\n",
            "   -------- ------------------------------- 16/72 [param]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   --------- ------------------------------ 17/72 [numcodecs]\n",
            "   ---------- ----------------------------- 18/72 [natsort]\n",
            "   ---------- ----------------------------- 18/72 [natsort]\n",
            "   ---------- ----------------------------- 19/72 [more_itertools]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ----------- ---------------------------- 21/72 [llvmlite]\n",
            "   ------------ --------------------------- 22/72 [legacy-api-wrap]\n",
            "   ------------ --------------------------- 23/72 [lazy-loader]\n",
            "   ------------- -------------------------- 25/72 [jmespath]\n",
            "   ------------- -------------------------- 25/72 [jmespath]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   -------------- ------------------------- 26/72 [imageio]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 27/72 [h5py]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   --------------- ------------------------ 28/72 [fonttools]\n",
            "   ---------------- ----------------------- 29/72 [fasteners]\n",
            "   ----------------- ---------------------- 31/72 [cycler]\n",
            "   ----------------- ---------------------- 32/72 [contourpy]\n",
            "   ----------------- ---------------------- 32/72 [contourpy]\n",
            "   ------------------ --------------------- 33/72 [colorcet]\n",
            "   ------------------- -------------------- 35/72 [array-api-compat]\n",
            "   ------------------- -------------------- 35/72 [array-api-compat]\n",
            "   ------------------- -------------------- 35/72 [array-api-compat]\n",
            "   ------------------- -------------------- 35/72 [array-api-compat]\n",
            "   -------------------- ------------------- 36/72 [aioitertools]\n",
            "   -------------------- ------------------- 37/72 [zarr]\n",
            "   -------------------- ------------------- 37/72 [zarr]\n",
            "   -------------------- ------------------- 37/72 [zarr]\n",
            "   -------------------- ------------------- 37/72 [zarr]\n",
            "   -------------------- ------------------- 37/72 [zarr]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 38/72 [scikit-image]\n",
            "   --------------------- ------------------ 39/72 [pyct]\n",
            "   ---------------------- ----------------- 40/72 [pooch]\n",
            "   ---------------------- ----------------- 40/72 [pooch]\n",
            "   ---------------------- ----------------- 41/72 [pims]\n",
            "   ---------------------- ----------------- 41/72 [pims]\n",
            "   ---------------------- ----------------- 41/72 [pims]\n",
            "   ---------------------- ----------------- 41/72 [pims]\n",
            "   ----------------------- ---------------- 42/72 [partd]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ----------------------- ---------------- 43/72 [pandas]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------ --------------- 44/72 [numba]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   ------------------------- -------------- 45/72 [matplotlib]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 47/72 [botocore]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   -------------------------- ------------- 48/72 [xarray]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 49/72 [statsmodels]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   --------------------------- ------------ 50/72 [seaborn]\n",
            "   ---------------------------- ----------- 51/72 [pynndescent]\n",
            "   ---------------------------- ----------- 52/72 [omnipath]\n",
            "   ---------------------------- ----------- 52/72 [omnipath]\n",
            "   ---------------------------- ----------- 52/72 [omnipath]\n",
            "   ---------------------------- ----------- 52/72 [omnipath]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 54/72 [geopandas]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------ --------- 55/72 [dask]\n",
            "   ------------------------------- -------- 56/72 [anndata]\n",
            "   ------------------------------- -------- 56/72 [anndata]\n",
            "   ------------------------------- -------- 56/72 [anndata]\n",
            "   ------------------------------- -------- 56/72 [anndata]\n",
            "   ------------------------------- -------- 56/72 [anndata]\n",
            "   -------------------------------- ------- 58/72 [xarray-dataclass]\n",
            "   -------------------------------- ------- 59/72 [umap-learn]\n",
            "   -------------------------------- ------- 59/72 [umap-learn]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 60/72 [datashader]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   --------------------------------- ------ 61/72 [dask-expr]\n",
            "   ---------------------------------- ----- 62/72 [aiobotocore]\n",
            "   ---------------------------------- ----- 62/72 [aiobotocore]\n",
            "   ---------------------------------- ----- 62/72 [aiobotocore]\n",
            "   ---------------------------------- ----- 62/72 [aiobotocore]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ----------------------------------- ---- 63/72 [xarray-spatial]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------ --- 65/72 [scanpy]\n",
            "   ------------------------------------- -- 67/72 [multiscale-spatial-image]\n",
            "   ------------------------------------- -- 67/72 [multiscale-spatial-image]\n",
            "   ------------------------------------- -- 68/72 [dask-image]\n",
            "   ------------------------------------- -- 68/72 [dask-image]\n",
            "   ------------------------------------- -- 68/72 [dask-image]\n",
            "   -------------------------------------- - 69/72 [ome-zarr]\n",
            "   -------------------------------------- - 69/72 [ome-zarr]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   -------------------------------------- - 70/72 [spatialdata]\n",
            "   ---------------------------------------  71/72 [squidpy]\n",
            "   ---------------------------------------  71/72 [squidpy]\n",
            "   ---------------------------------------  71/72 [squidpy]\n",
            "   ---------------------------------------  71/72 [squidpy]\n",
            "   ---------------------------------------  71/72 [squidpy]\n",
            "   ---------------------------------------- 72/72 [squidpy]\n",
            "\n",
            "Successfully installed aiobotocore-2.25.2 aioitertools-0.13.0 anndata-0.11.4 array-api-compat-1.12.0 asciitree-0.3.3 botocore-1.40.70 cloudpickle-3.1.2 colorcet-3.1.0 contourpy-1.3.2 cycler-0.12.1 dask-2024.11.2 dask-expr-1.1.19 dask-image-2025.11.0 datashader-0.18.2 docrep-0.3.2 fasteners-0.20 fonttools-4.60.1 geopandas-1.1.1 h5py-3.15.1 imageio-2.37.2 inflect-7.5.0 jmespath-1.0.1 kiwisolver-1.4.9 lazy-loader-0.4 legacy-api-wrap-1.5 llvmlite-0.45.1 locket-1.0.0 matplotlib-3.10.7 matplotlib-scalebar-0.9.0 more_itertools-10.8.0 multipledispatch-1.0.0 multiscale-spatial-image-2.0.3 natsort-8.4.0 numba-0.62.1 numcodecs-0.13.1 ome-zarr-0.11.1 omnipath-1.0.12 pandas-2.3.3 param-2.3.0 partd-1.4.2 patsy-1.0.2 pims-0.7 pooch-1.8.2 pyarrow-22.0.0 pyct-0.6.0 pynndescent-0.5.13 pyogrio-0.11.1 pyparsing-3.2.5 pyproj-3.7.1 pytz-2025.2 s3fs-2025.7.0 scanpy-1.11.5 scikit-image-0.25.2 seaborn-0.13.2 session-info2-0.2.3 slicerator-1.1.0 spatial-image-1.2.3 spatialdata-0.5.0 squidpy-1.6.5 statsmodels-0.14.5 tifffile-2025.5.10 toolz-1.1.0 typeguard-4.4.4 tzdata-2025.2 umap-learn-0.5.9.post2 validators-0.35.0 wrapt-1.17.3 xarray-2025.6.1 xarray-dataclass-3.0.0 xarray-schema-0.0.3 xarray-spatial-0.4.0 zarr-2.18.3\n"
          ]
        }
      ],
      "source": [
        "!pip install squidpy scanpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Ql0AhMu6UZDi",
      "metadata": {
        "id": "Ql0AhMu6UZDi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting langchain\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8e/4a/02c14af46fa79ce7b02a0f8af46f5905cc7e8b647a5f1a7c793c03ac5063/langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "Collecting langgraph\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/84/a3/fdf6ecd0e44cb02d20afe7d0fb64c748a749f4b2e011bf9a785a32642367/langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.4 (from langchain)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6e/ee/aaf2343a35080154c82ceb110e03dd00f15459bc72e518df51724cbc41a9/langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain) (2.11.7)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/e3/616e3a7ff737d98c1bbb5700dd62278914e2a9ded09a79a1fa93cf24ce12/langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/69/14/a83e50129f66df783a68acb89e7b3e9c39b5c128a8748e961bc2b187f003/langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/66/05/b2d34e16638241e6f27a6946d28160d4b8b641383787646d41a3727e0896/langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/5c/521a3d8295e2e7caea67032e65554866293b6dc8e934bd86be8cc1f7b955/langsmith-0.4.43-py3-none-any.whl (410 kB)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.2)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (4.14.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d8/c6/1a9fa122cb5deb10b067bbaa43165b12291a914cc0ce364988ff17bbf405/ormsgpack-1.12.0-cp310-cp310-win_amd64.whl (112 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/69/18a778c9de3702b19880e73c9866b91cc85f904b885d816ba1ab318b223c/orjson-3.11.4-cp310-cp310-win_amd64.whl (131 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.4)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/93/90/96d50ad417a8ace5f841b3228e93d1bb13e6ad356737f42e2dde30d8bd68/zstandard-0.25.0-cp310-cp310-win_amd64.whl (506 kB)\n",
            "Requirement already satisfied: anyio in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Installing collected packages: zstandard, tenacity, ormsgpack, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "\n",
            "   -- -------------------------------------  1/14 [tenacity]\n",
            "   -- -------------------------------------  1/14 [tenacity]\n",
            "   ----------- ----------------------------  4/14 [jsonpointer]\n",
            "   -------------- -------------------------  5/14 [requests-toolbelt]\n",
            "   -------------- -------------------------  5/14 [requests-toolbelt]\n",
            "   -------------- -------------------------  5/14 [requests-toolbelt]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   ---------------------- -----------------  8/14 [langgraph-sdk]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ---------------------------- ----------- 10/14 [langgraph-checkpoint]\n",
            "   ---------------------------- ----------- 10/14 [langgraph-checkpoint]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ---------------------------------- ----- 12/14 [langgraph]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ------------------------------------- -- 13/14 [langchain]\n",
            "   ---------------------------------------- 14/14 [langchain]\n",
            "\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.7 langchain-core-1.0.5 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 langsmith-0.4.43 orjson-3.11.4 ormsgpack-1.12.0 requests-toolbelt-1.0.0 tenacity-9.1.2 zstandard-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2rWZzgKFUUNe",
      "metadata": {
        "id": "2rWZzgKFUUNe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting langchain_google_vertexai\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/55/fb3c43075541f7723d67b754ffd36ae47330033343379f4fa5eaf3736881/langchain_google_vertexai-3.0.3-py3-none-any.whl (100 kB)\n",
            "Collecting bottleneck<2.0.0,>=1.4.0 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/75/8f0e8e266ea99ffbc69500a927f0c114a07fe465bfbc59871d6fe22d9ee0/bottleneck-1.6.0-cp310-cp310-win_amd64.whl (113 kB)\n",
            "Collecting google-cloud-aiplatform<2.0.0,>=1.97.0 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9e/bc/105e95a8fab5fd3a5bc503a80065bc32aac21746fc774a318b480f137874/google_cloud_aiplatform-1.127.0-py2.py3-none-any.whl (8.1 MB)\n",
            "     ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.5/8.1 MB 16.4 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 1.3/8.1 MB 4.2 MB/s eta 0:00:02\n",
            "     ---------- ----------------------------- 2.1/8.1 MB 4.0 MB/s eta 0:00:02\n",
            "     -------------- ------------------------- 2.9/8.1 MB 4.4 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 4.2/8.1 MB 4.4 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 4.7/8.1 MB 4.4 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 5.8/8.1 MB 4.3 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 6.6/8.1 MB 4.4 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 7.6/8.1 MB 4.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 8.1/8.1 MB 4.3 MB/s eta 0:00:00\n",
            "Collecting google-cloud-storage<4.0.0,>=2.18.0 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/ef/3b57bf617ee0c79450c1ff211d1eb888db8fc1050ac74b3e52cc6ed86e63/google_cloud_storage-3.6.0-py3-none-any.whl (299 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/fd/6668e5aec43ab844de6fc74927e155a3b37bf40d7c3790e49fc0406b6578/httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain_google_vertexai) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain_google_vertexai) (1.0.5)\n",
            "Collecting numexpr<3.0.0,>=2.8.6 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/af/26773a246716922794388786529e5640676399efabb0ee217ce034df9d27/numexpr-2.14.1-cp310-cp310-win_amd64.whl (160 kB)\n",
            "Collecting pyarrow<22.0.0,>=19.0.1 (from langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7b/f5/c372ef60593d713e8bfbb7e0c743501605f0ad00719146dc075faf11172b/pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
            "     ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.8/26.2 MB 4.2 MB/s eta 0:00:07\n",
            "     - -------------------------------------- 1.3/26.2 MB 4.5 MB/s eta 0:00:06\n",
            "     --- ------------------------------------ 2.6/26.2 MB 4.3 MB/s eta 0:00:06\n",
            "     ---- ----------------------------------- 3.1/26.2 MB 4.3 MB/s eta 0:00:06\n",
            "     ------ --------------------------------- 4.5/26.2 MB 4.3 MB/s eta 0:00:06\n",
            "     ------- -------------------------------- 5.2/26.2 MB 4.3 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 6.3/26.2 MB 4.3 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 7.1/26.2 MB 4.3 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 7.9/26.2 MB 4.3 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 8.7/26.2 MB 4.2 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 10.0/26.2 MB 4.4 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 10.7/26.2 MB 4.4 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 11.5/26.2 MB 4.3 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 12.1/26.2 MB 4.2 MB/s eta 0:00:04\n",
            "     ------------------- -------------------- 12.8/26.2 MB 4.1 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 13.4/26.2 MB 4.0 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 14.2/26.2 MB 4.0 MB/s eta 0:00:04\n",
            "     ---------------------- ----------------- 14.7/26.2 MB 3.9 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 15.5/26.2 MB 3.9 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 16.0/26.2 MB 3.8 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 16.5/26.2 MB 3.7 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 16.8/26.2 MB 3.7 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 17.3/26.2 MB 3.6 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 17.6/26.2 MB 3.6 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 18.1/26.2 MB 3.4 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 18.4/26.2 MB 3.4 MB/s eta 0:00:03\n",
            "     ---------------------------- ----------- 18.9/26.2 MB 3.3 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 19.1/26.2 MB 3.3 MB/s eta 0:00:03\n",
            "     ----------------------------- ---------- 19.4/26.2 MB 3.2 MB/s eta 0:00:03\n",
            "     ------------------------------ --------- 19.9/26.2 MB 3.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 20.2/26.2 MB 3.1 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 20.7/26.2 MB 3.1 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 21.0/26.2 MB 3.0 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 21.2/26.2 MB 3.0 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 21.5/26.2 MB 2.9 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 22.0/26.2 MB 2.9 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 22.3/26.2 MB 2.9 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 22.5/26.2 MB 2.9 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 23.1/26.2 MB 2.8 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 23.3/26.2 MB 2.8 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 23.9/26.2 MB 2.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 24.1/26.2 MB 2.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 24.6/26.2 MB 2.7 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 25.2/26.2 MB 2.7 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 25.4/26.2 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------  26.0/26.2 MB 2.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 26.2/26.2 MB 2.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain_google_vertexai) (2.11.7)\n",
            "Requirement already satisfied: validators<1.0.0,>=0.22.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain_google_vertexai) (0.35.0)\n",
            "Requirement already satisfied: numpy in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from bottleneck<2.0.0,>=1.4.0->langchain_google_vertexai) (2.2.6)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/d4/90197b416cb61cefd316964fd9e7bd8324bcbafabf40eef14a9f20b81974/google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
            "Collecting google-auth<3.0.0,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/d1/385110a9ae86d91cc14c5282c61fe9f4dc41c0b9f7d423c6ad77038c4448/google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4e/6d/280c4c2ce28b1593a19ad5239c8b826871fc6ec275c21afc8e1820108039/proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/79/8780a378c650e3df849b73de8b13cf5412f521ca2ff9b78a45c247029440/protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
            "Requirement already satisfied: packaging>=14.3 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (25.0)\n",
            "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/3c/c8cada9ec282b29232ed9aed5a0b5cca6cf5367cb2ffa8ad0d2583d743f1/google_cloud_bigquery-3.38.0-py3-none-any.whl (259 kB)\n",
            "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8c/93/5aef41a5f146ad4559dd7040ae5fa8e7ddcab4dfadbef6cb4b66d775e690/google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
            "Requirement already satisfied: shapely<3.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.1.1)\n",
            "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/28/0185dcda66f1994171067cfdb0e44a166450239d5b11b3a8a281dd2da459/google_genai-1.51.0-py3-none-any.whl (260 kB)\n",
            "Requirement already satisfied: typing_extensions in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (4.14.1)\n",
            "Collecting docstring_parser<1 (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/55/e2/2537ebcff11c1ee1ff17d8d0b6f4db75873e3b0fb32c2d4a2ee31ecb310a/docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c4/ab/09169d5a4612a5f92490806649ac8d41e3ec9129c636754575b3553f4ea4/googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.32.4)\n",
            "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/30/d3d2adcbb6dd3ff59d6ac3df6ef830e02b437fb5c90990429fd180e52f30/grpcio-1.76.0-cp310-cp310-win_amd64.whl (4.7 MB)\n",
            "     ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
            "     ---- ----------------------------------- 0.5/4.7 MB 1.3 MB/s eta 0:00:04\n",
            "     -------- ------------------------------- 1.0/4.7 MB 1.4 MB/s eta 0:00:03\n",
            "     ----------- ---------------------------- 1.3/4.7 MB 1.4 MB/s eta 0:00:03\n",
            "     ------------- -------------------------- 1.6/4.7 MB 1.5 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 2.1/4.7 MB 1.6 MB/s eta 0:00:02\n",
            "     -------------------- ------------------- 2.4/4.7 MB 1.6 MB/s eta 0:00:02\n",
            "     ------------------------ --------------- 2.9/4.7 MB 1.7 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 3.4/4.7 MB 1.8 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 3.9/4.7 MB 1.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 4.5/4.7 MB 1.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 4.7/4.7 MB 1.9 MB/s eta 0:00:00\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8c/cc/27ba60ad5a5f2067963e6a858743500df408eb5855e98be778eaef8c9b02/grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/46/eb6eca305c77a4489affe1c5d8f4cae82f285d9addd8de4ec084a7184221/cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/89/20/bfa472e327c8edee00f04beecc80baeddd2ab33ee0e86fd7654da49d45e9/google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1f/0b/93afde9cfe012260e9fe1522f35c9b72d6ee222f316586b1f23ecf44d518/google_resumable_media-2.8.0-py3-none-any.whl (81 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.9.0.post0)\n",
            "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4a/bd/330a1bbdb1afe0b96311249e699b6dc9cfc17916394fd4503ac5aca2514b/grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
            "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=2.18.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/bf/21ac7bb305cd7c1a6de9c52f71db0868e104a5b573a4977cd9d0ff830f82/google_crc32c-1.7.1-cp310-cp310-win_amd64.whl (33 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (4.9.0)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (9.1.2)\n",
            "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1c/46/aca7082012768bb98e5608f01658ff3ac8437e563eca41cf068bd5849a5e/websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.3.1)\n",
            "Requirement already satisfied: certifi in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx<1.0.0,>=0.28.0->langchain_google_vertexai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx<1.0.0,>=0.28.0->langchain_google_vertexai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.0->langchain_google_vertexai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (0.4.43)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (6.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_google_vertexai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->langchain_google_vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->langchain_google_vertexai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->langchain_google_vertexai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.5.0)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: websockets, pyasn1, pyarrow, protobuf, numexpr, httpx-sse, grpcio, google-crc32c, docstring_parser, cachetools, bottleneck, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-genai, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, langchain_google_vertexai\n",
            "\n",
            "   ----------------------------------------  0/27 [websockets]\n",
            "   ----------------------------------------  0/27 [websockets]\n",
            "   ----------------------------------------  0/27 [websockets]\n",
            "   ----------------------------------------  0/27 [websockets]\n",
            "   ----------------------------------------  0/27 [websockets]\n",
            "   - --------------------------------------  1/27 [pyasn1]\n",
            "   - --------------------------------------  1/27 [pyasn1]\n",
            "   - --------------------------------------  1/27 [pyasn1]\n",
            "  Attempting uninstall: pyarrow\n",
            "   - --------------------------------------  1/27 [pyasn1]\n",
            "    Found existing installation: pyarrow 22.0.0\n",
            "   - --------------------------------------  1/27 [pyasn1]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "    Uninstalling pyarrow-22.0.0:\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "      Successfully uninstalled pyarrow-22.0.0\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   -- -------------------------------------  2/27 [pyarrow]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ---- -----------------------------------  3/27 [protobuf]\n",
            "   ----- ----------------------------------  4/27 [numexpr]\n",
            "   -------- -------------------------------  6/27 [grpcio]\n",
            "   -------- -------------------------------  6/27 [grpcio]\n",
            "   -------- -------------------------------  6/27 [grpcio]\n",
            "   -------- -------------------------------  6/27 [grpcio]\n",
            "   -------- -------------------------------  6/27 [grpcio]\n",
            "   ---------- -----------------------------  7/27 [google-crc32c]\n",
            "   ----------- ----------------------------  8/27 [docstring_parser]\n",
            "   ----------- ----------------------------  8/27 [docstring_parser]\n",
            "   -------------- ------------------------- 10/27 [bottleneck]\n",
            "   -------------- ------------------------- 10/27 [bottleneck]\n",
            "   ---------------- ----------------------- 11/27 [rsa]\n",
            "   ---------------- ----------------------- 11/27 [rsa]\n",
            "   ---------------- ----------------------- 11/27 [rsa]\n",
            "   ---------------- ----------------------- 11/27 [rsa]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ----------------- ---------------------- 12/27 [pyasn1-modules]\n",
            "   ------------------- -------------------- 13/27 [proto-plus]\n",
            "   ------------------- -------------------- 13/27 [proto-plus]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   -------------------- ------------------- 14/27 [googleapis-common-protos]\n",
            "   ---------------------- ----------------- 15/27 [google-resumable-media]\n",
            "   ---------------------- ----------------- 15/27 [google-resumable-media]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   ------------------------- -------------- 17/27 [google-auth]\n",
            "   -------------------------- ------------- 18/27 [grpc-google-iam-v1]\n",
            "   ---------------------------- ----------- 19/27 [google-genai]\n",
            "   ---------------------------- ----------- 19/27 [google-genai]\n",
            "   ---------------------------- ----------- 19/27 [google-genai]\n",
            "   ---------------------------- ----------- 19/27 [google-genai]\n",
            "   ---------------------------- ----------- 19/27 [google-genai]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ----------------------------- ---------- 20/27 [google-api-core]\n",
            "   ------------------------------- -------- 21/27 [google-cloud-core]\n",
            "   -------------------------------- ------- 22/27 [google-cloud-storage]\n",
            "   -------------------------------- ------- 22/27 [google-cloud-storage]\n",
            "   -------------------------------- ------- 22/27 [google-cloud-storage]\n",
            "   -------------------------------- ------- 22/27 [google-cloud-storage]\n",
            "   -------------------------------- ------- 22/27 [google-cloud-storage]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   -------------------------------- ----- 23/27 [google-cloud-resource-manager]\n",
            "   ----------------------------------- ---- 24/27 [google-cloud-bigquery]\n",
            "   ----------------------------------- ---- 24/27 [google-cloud-bigquery]\n",
            "   ----------------------------------- ---- 24/27 [google-cloud-bigquery]\n",
            "   ----------------------------------- ---- 24/27 [google-cloud-bigquery]\n",
            "   ----------------------------------- ---- 24/27 [google-cloud-bigquery]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   ------------------------------------- -- 25/27 [google-cloud-aiplatform]\n",
            "   -------------------------------------- - 26/27 [langchain_google_vertexai]\n",
            "   -------------------------------------- - 26/27 [langchain_google_vertexai]\n",
            "   -------------------------------------- - 26/27 [langchain_google_vertexai]\n",
            "   ---------------------------------------- 27/27 [langchain_google_vertexai]\n",
            "\n",
            "Successfully installed bottleneck-1.6.0 cachetools-6.2.2 docstring_parser-0.17.0 google-api-core-2.28.1 google-auth-2.43.0 google-cloud-aiplatform-1.127.0 google-cloud-bigquery-3.38.0 google-cloud-core-2.5.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.6.0 google-crc32c-1.7.1 google-genai-1.51.0 google-resumable-media-2.8.0 googleapis-common-protos-1.72.0 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 httpx-sse-0.4.3 langchain_google_vertexai-3.0.3 numexpr-2.14.1 proto-plus-1.26.1 protobuf-6.33.1 pyarrow-21.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 websockets-15.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_google_vertexai\n",
        "# error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Hbn04DkXDYqi",
      "metadata": {
        "id": "Hbn04DkXDYqi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting synapseclient\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5f/2f/9bc58f8d646988e0ebfaee73b1424657d57d152f7a5d03d38aea40d2fdec/synapseclient-4.10.0-py3-none-any.whl (599 kB)\n",
            "     ---------------------------------------- 0.0/599.4 kB ? eta -:--:--\n",
            "     --------------------------------- ---- 524.3/599.4 kB 2.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- 599.4/599.4 kB 3.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests<3.0,>=2.22.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (2.32.4)\n",
            "Collecting urllib3<2,>=1.26.18 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/33/cf/8435d5a7159e2a9c83a95896ed596f68cf798005fe107cc655b5c5c14704/urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Requirement already satisfied: deprecated<2.0,>=1.2.4 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (1.3.1)\n",
            "Collecting opentelemetry-api>=1.21.0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/a2/d86e01c28300bd41bab8f18afd613676e2bd63515417b77636fc1add426f/opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "Collecting opentelemetry-sdk>=1.21.0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/2e/e93777a95d7d9c40d270a371392b6d6f1ff170c2a3cb32d6176741b5b723/opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.21.0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/77/154004c99fb9f291f74aa0822a2f5bbf565a72d8126b3a1b63ed8e5f83c7/opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
            "Collecting opentelemetry-instrumentation-httpx>=0.48b0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/58/16/c1e0745d20af392ec9060693531d7f01239deb2d81e460d0c379719691b8/opentelemetry_instrumentation_httpx-0.59b0-py3-none-any.whl (15 kB)\n",
            "Collecting opentelemetry-instrumentation-requests>=0.48b0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/ea/c282ba418b2669e4f730cb3f68b02a0ca65f4baf801e971169a4cc449ffb/opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl (12 kB)\n",
            "Collecting opentelemetry-instrumentation-threading>=0.48b0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b8/50/32d29076aaa1c91983cdd3ca8c6bb4d344830cd7d87a7c0fdc2d98c58509/opentelemetry_instrumentation_threading-0.59b0-py3-none-any.whl (9.3 kB)\n",
            "Collecting opentelemetry-instrumentation-urllib>=0.48b0 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/29/94/0e87ffe1edfdda27e401d8ebab71ee3dd9ceaac11f98b8f5c190820a317f/opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: nest-asyncio~=1.6.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (1.6.0)\n",
            "Collecting asyncio-atexit~=1.0.1 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/65/10/d6abaefa57a52646651fd0383c056280b0853c0106229ece6bb38cd14463/asyncio_atexit-1.0.1-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (0.28.1)\n",
            "Requirement already satisfied: httpcore>=1.0.9 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from synapseclient) (4.67.1)\n",
            "Collecting async-lru~=2.0.4 (from synapseclient)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/03/49/d10027df9fce941cb8184e78a02857af36360d33e1721df81c5ed2179a1a/async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Collecting psutil~=5.9.8 (from synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/93/52/3e39d26feae7df0aa0fd510b14012c3678b36ed068f7d78b8d8784d61f0e/psutil-5.9.8-cp37-abi3-win_amd64.whl (255 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from async-lru~=2.0.4->synapseclient) (4.14.1)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from deprecated<2.0,>=1.2.4->synapseclient) (1.17.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests<3.0,>=2.22.0->synapseclient) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests<3.0,>=2.22.0->synapseclient) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests<3.0,>=2.22.0->synapseclient) (2025.7.14)\n",
            "Requirement already satisfied: colorama in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from tqdm<5.0,>=4.66.2->synapseclient) (0.4.6)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpcore>=1.0.9->synapseclient) (0.16.0)\n",
            "Requirement already satisfied: anyio in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from httpx>=0.27.0->synapseclient) (4.9.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from opentelemetry-api>=1.21.0->synapseclient) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.21.0->synapseclient) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a7/9e/55a41c9601191e8cd8eb626b54ee6827b9c9d4a46d736f32abc80d8039fc/opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b6/6a/82b68b14efca5150b2632f3692d627afa76b77378c4999f2648979409528/opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-http>=1.21.0->synapseclient) (6.33.1)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.21.0->synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/24/7d/c88d7b15ba8fe5c6b8f93be50fc11795e9fc05386c44afaf6b76fe191f9b/opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-httpx>=0.48b0->synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/f5/7a40ff3f62bfe715dad2f633d7f1174ba1a7dd74254c15b2558b3401262a/opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
            "Collecting opentelemetry-util-http==0.59b0 (from opentelemetry-instrumentation-httpx>=0.48b0->synapseclient)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/20/56/62282d1d4482061360449dacc990c89cad0fc810a2ed937b636300f55023/opentelemetry_util_http-0.59b0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: packaging>=18.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-httpx>=0.48b0->synapseclient) (25.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio->httpx>=0.27.0->synapseclient) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anyio->httpx>=0.27.0->synapseclient) (1.3.1)\n",
            "Installing collected packages: urllib3, psutil, opentelemetry-util-http, opentelemetry-proto, asyncio-atexit, async-lru, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-threading, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-httpx, opentelemetry-exporter-otlp-proto-http, synapseclient\n",
            "\n",
            "  Attempting uninstall: urllib3\n",
            "\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "  Attempting uninstall: psutil\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "    Found existing installation: psutil 7.0.0\n",
            "   ----------------------------------------  0/17 [urllib3]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "    Uninstalling psutil-7.0.0:\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   -- -------------------------------------  1/17 [psutil]\n",
            "   ---- -----------------------------------  2/17 [opentelemetry-util-http]\n",
            "   ------- --------------------------------  3/17 [opentelemetry-proto]\n",
            "   ------- --------------------------------  3/17 [opentelemetry-proto]\n",
            "   --------- ------------------------------  4/17 [asyncio-atexit]\n",
            "   --------- -----------------  6/17 [opentelemetry-exporter-otlp-proto-common]\n",
            "   ---------------- -----------------------  7/17 [opentelemetry-api]\n",
            "   ---------------- -----------------------  7/17 [opentelemetry-api]\n",
            "   ---------------- -----------------------  7/17 [opentelemetry-api]\n",
            "   ---------------- -----------------------  7/17 [opentelemetry-api]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------- -----------------  8/17 [opentelemetry-semantic-conventions]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   --------------------- ------------------  9/17 [opentelemetry-sdk]\n",
            "   ---------------------- --------------- 10/17 [opentelemetry-instrumentation]\n",
            "   ---------------------- --------------- 10/17 [opentelemetry-instrumentation]\n",
            "   ------------------- -------- 12/17 [opentelemetry-instrumentation-threading]\n",
            "   ------------------------- --- 15/17 [opentelemetry-exporter-otlp-proto-http]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ------------------------------------- -- 16/17 [synapseclient]\n",
            "   ---------------------------------------- 17/17 [synapseclient]\n",
            "\n",
            "Successfully installed async-lru-2.0.5 asyncio-atexit-1.0.1 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-httpx-0.59b0 opentelemetry-instrumentation-requests-0.59b0 opentelemetry-instrumentation-threading-0.59b0 opentelemetry-instrumentation-urllib-0.59b0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-util-http-0.59b0 psutil-5.9.8 synapseclient-4.10.0 urllib3-1.26.20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "crawl4ai 0.7.1 requires psutil>=6.1.1, but you have psutil 5.9.8 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install synapseclient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "SMNOPCDx1W98",
      "metadata": {
        "id": "SMNOPCDx1W98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting commot\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/60/39/55cd0a1c949162ceba88f3fa6fa823801aa5ecd25550b761f4755d64b31a/commot-0.0.3-py3-none-any.whl (118 kB)\n",
            "Requirement already satisfied: anndata>=0.7.6 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (0.11.4)\n",
            "Collecting karateclub>=1.2.2 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/dd/03f2234b88c67223f8841ea3fa7a66555a98c87c9ba37f425713752c0a4f/karateclub-1.3.3.tar.gz (64 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting leidenalg>=0.9.0 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/15/7d459a8e2a43f17c1db129b997b7bb7aa7f000a0967bab87c28b8c5cf448/leidenalg-0.11.0-cp38-abi3-win_amd64.whl (2.0 MB)\n",
            "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
            "     ---------- ----------------------------- 0.5/2.0 MB 17.5 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 1.3/2.0 MB 4.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.0/2.0 MB 4.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: networkx>=2.5.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (2.2.6)\n",
            "Requirement already satisfied: pandas>=1.3.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (2.3.3)\n",
            "Collecting plotly>=5.3.1 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/c3/3031c931098de393393e1f93a38dc9ed6805d86bb801acc3cf2d5bd1e6b7/plotly-6.5.0-py3-none-any.whl (9.9 MB)\n",
            "     ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
            "     --- ------------------------------------ 0.8/9.9 MB 5.6 MB/s eta 0:00:02\n",
            "     ------ --------------------------------- 1.6/9.9 MB 4.6 MB/s eta 0:00:02\n",
            "     ---------- ----------------------------- 2.6/9.9 MB 4.6 MB/s eta 0:00:02\n",
            "     ------------- -------------------------- 3.4/9.9 MB 4.7 MB/s eta 0:00:02\n",
            "     ---------------- ----------------------- 4.2/9.9 MB 4.6 MB/s eta 0:00:02\n",
            "     ---------------------- ----------------- 5.5/9.9 MB 4.5 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 6.6/9.9 MB 4.6 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 7.3/9.9 MB 4.5 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 8.1/9.9 MB 4.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 9.4/9.9 MB 4.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 9.9/9.9 MB 4.5 MB/s eta 0:00:00\n",
            "Collecting pot>=0.8.0 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c4/21/9731ac0b125f755bb513a4ee081dca0ca5335e9059fb3332dd7c50d28415/pot-0.9.6.post1-cp310-cp310-win_amd64.whl (458 kB)\n",
            "Collecting pysal>=2.6.0 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d3/f6/175477ea92049acc28bd8e34423ad101847680d1649ee46940ac5abd13f4/pysal-25.7-py3-none-any.whl (17 kB)\n",
            "Collecting python-igraph>=0.9.9 (from commot)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/31/5f/567fa047076d32d321bdafa248905a7186d2acee4916b046b11417af10d9/python_igraph-1.0.0-py3-none-any.whl (9.2 kB)\n",
            "Collecting python-louvain>=0.15 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7c/0d/8787b021d52eb8764c0bb18ab95f720cf554902044c6a5cb1865daf45763/python-louvain-0.16.tar.gz (204 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: scanpy>=1.8.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (1.11.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (1.7.1)\n",
            "Requirement already satisfied: importlib-metadata in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from commot) (8.7.0)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (1.12.0)\n",
            "Requirement already satisfied: exceptiongroup in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (1.3.0)\n",
            "Requirement already satisfied: h5py>=3.7 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (3.15.1)\n",
            "Requirement already satisfied: natsort in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (8.4.0)\n",
            "Requirement already satisfied: packaging>=24.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (25.0)\n",
            "Requirement already satisfied: scipy>1.8 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from anndata>=0.7.6->commot) (1.15.3)\n",
            "INFO: pip is looking at multiple versions of karateclub to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting karateclub>=1.2.2 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4b/50/f6eb75ed00cac78a8cb40272a4e8216a3c577a85ac6493019ebfde47fb46/karateclub-1.3.2.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8a/61/adff77aaa0fd37e3e4f4277e4376879ad84ec7d55f7c21fb0e0cf7d3f0e0/karateclub-1.3.1.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/73/2f/e1d8112056b1da336c0b05a6893f3143f5468ee0d71f3f32d6513da667bb/karateclub-1.3.0.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting networkx>=2.5.1 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e9/93/aa6613aa70d6eb4868e667068b5a11feca9645498fd31b954b6c4bb82fa5/networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "     ---------------- ----------------------- 0.8/1.9 MB 3.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.9/1.9 MB 4.4 MB/s eta 0:00:00\n",
            "Collecting decorator==4.4.2 (from karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: tqdm in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from karateclub>=1.2.2->commot) (4.67.1)\n",
            "Collecting pygsp (from karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/78/20/e70bb515584fafe1114be442b47554df6a22c57b7bd2641a6dcfabe9004b/pygsp-0.6.1-py3-none-any.whl (1.9 MB)\n",
            "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "     ---------------- ----------------------- 0.8/1.9 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
            "Collecting gensim>=4.0.0 (from karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/53/fe/e483909cfbfa8cc4bfd30aa9fb5170c04316cc22f23c9906529f08fb9095/gensim-4.4.0-cp310-cp310-win_amd64.whl (24.4 MB)\n",
            "     ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.8/24.4 MB 4.2 MB/s eta 0:00:06\n",
            "     -- ------------------------------------- 1.6/24.4 MB 4.2 MB/s eta 0:00:06\n",
            "     ---- ----------------------------------- 2.6/24.4 MB 4.3 MB/s eta 0:00:06\n",
            "     ----- ---------------------------------- 3.4/24.4 MB 4.3 MB/s eta 0:00:05\n",
            "     ------ --------------------------------- 4.2/24.4 MB 4.1 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 5.2/24.4 MB 4.4 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 6.3/24.4 MB 4.3 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 7.1/24.4 MB 4.3 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 7.9/24.4 MB 4.3 MB/s eta 0:00:04\n",
            "     -------------- ------------------------- 8.7/24.4 MB 4.3 MB/s eta 0:00:04\n",
            "     --------------- ------------------------ 9.7/24.4 MB 4.3 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 10.5/24.4 MB 4.2 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 11.5/24.4 MB 4.2 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 12.3/24.4 MB 4.3 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 13.4/24.4 MB 4.3 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 14.4/24.4 MB 4.3 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 15.2/24.4 MB 4.3 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 16.0/24.4 MB 4.2 MB/s eta 0:00:02\n",
            "     --------------------------- ------------ 17.0/24.4 MB 4.3 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 17.8/24.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 18.4/24.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 19.1/24.4 MB 4.2 MB/s eta 0:00:02\n",
            "     --------------------------------- ------ 20.2/24.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 21.0/24.4 MB 4.2 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 22.0/24.4 MB 4.2 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 22.8/24.4 MB 4.2 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 23.6/24.4 MB 4.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 24.4/24.4 MB 4.1 MB/s eta 0:00:00\n",
            "Collecting karateclub>=1.2.2 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1f/28/6b559f500b8d01547ddd9fda78da10b7a7ea8ed135288e387df552b73f12/karateclub-1.2.4.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/97/4dd18e220feef0d0dc061f06b9ebae077739f31cfda7464172902248010b/karateclub-1.2.3.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cb/82/80e6d419a76fa57069b09b929cb8628e2aca8e50a00aa2bfa081b2239351/karateclub-1.2.2.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: six in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from karateclub>=1.2.2->commot) (1.17.0)\n",
            "Collecting python-Levenshtein (from karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7b/5b/26e3cca2589252ceabf964ba81514e6f48556553c9c2766e1a0fdceec696/python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\n",
            "Collecting smart_open>=1.8.1 (from gensim>=4.0.0->karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ad/95/bc978be7ea0babf2fb48a414b6afaad414c6a9e8b1eafc5b8a53c030381a/smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
            "Collecting igraph<2.0,>=1.0.0 (from leidenalg>=0.9.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/77/a85b3745cf40a0572bae2de8cd9c2a2a8af78e5cf3e880fc0a249114e609/igraph-1.0.0-cp39-abi3-win_amd64.whl (3.2 MB)\n",
            "     ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
            "     ------ --------------------------------- 0.5/3.2 MB 4.2 MB/s eta 0:00:01\n",
            "     ------------------- -------------------- 1.6/3.2 MB 4.0 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 2.4/3.2 MB 4.6 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 3.2/3.2 MB 4.0 MB/s eta 0:00:00\n",
            "Collecting texttable>=1.6.2 (from igraph<2.0,>=1.0.0->leidenalg>=0.9.0->commot)\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pandas>=1.3.5->commot) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pandas>=1.3.5->commot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pandas>=1.3.5->commot) (2025.2)\n",
            "Collecting narwhals>=1.15.1 (from plotly>=5.3.1->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/9a/c6f79de7ba3a0a8473129936b7b90aa461d3d46fec6f1627672b1dccf4e9/narwhals-2.12.0-py3-none-any.whl (425 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pysal>=2.6.0->commot) (4.13.4)\n",
            "Requirement already satisfied: geopandas>=0.10.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pysal>=2.6.0->commot) (1.1.1)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pysal>=2.6.0->commot) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.27 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pysal>=2.6.0->commot) (2.32.4)\n",
            "Requirement already satisfied: shapely>=2.0.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pysal>=2.6.0->commot) (2.1.1)\n",
            "Collecting libpysal>=4.13.0 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/59/c0/aea9a0b0d180f51d742428f211eafe7bf72139589fb2f484839e7d39efca/libpysal-4.13.0-py3-none-any.whl (2.8 MB)\n",
            "     ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
            "     ----------- ---------------------------- 0.8/2.8 MB 4.2 MB/s eta 0:00:01\n",
            "     -------------------------- ------------- 1.8/2.8 MB 4.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 2.6/2.8 MB 4.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 2.8/2.8 MB 4.4 MB/s eta 0:00:00\n",
            "Collecting access>=1.1.9 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/e0/be59a75ad3d0b0fea7f8c6c55439772c4bb791406f3653aa25880ec68d7f/access-1.1.9-py3-none-any.whl (21 kB)\n",
            "INFO: pip is looking at multiple versions of pysal to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pysal>=2.6.0 (from commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/cc/38/c5c1e363b803c311f95d25cd1a0f54f5a5c41c3ca99c61b631e9bb915f71/pysal-25.1-py3-none-any.whl (17 kB)\n",
            "Collecting esda>=2.6.0 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5b/de/729ecc562edbd412ca2158cda78105c0208656cbbf2e6e70000c59d3ab9e/esda-2.7.0-py3-none-any.whl (142 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3b/d2/e6b32499fd212ac7f6d2a5db8343460c790a394d9742d96e88f4cca90173/giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "Collecting inequality>=1.1.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8e/a8/89fa9caf102a92e5075edaba8d81694be9ffae3fa8e4e9899151fc2ee0a8/inequality-1.1.1-py3-none-any.whl (29 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/17/99/5bd2e1cebcbf94076b8009170aee32c9a76fc65d645698b72e4c6580ea62/pointpats-2.5.2-py3-none-any.whl (63 kB)\n",
            "Collecting segregation>=2.5.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f5/56/48d0f69b856d3db2eda07e842f64fab67bcbca6df957e8768687b281ecbd/segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/29/04/8f6b281e28cc090f368f5eee126d8fd72f60ed9a318893a54989918b048b/spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4b/e8/464f7fc5f1daf1505211f42619143ad6f7634fda8f35a3758fc08aefc8a8/mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "Collecting momepy>=0.9.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f0/62/772a17a5e689d0f81e1dda40e06c94a84faf0cb12fe623f0992f08a0a991/momepy-0.9.1-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "     ------------------ --------------------- 0.8/1.7 MB 4.2 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 1.6/1.7 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.7/1.7 MB 3.9 MB/s eta 0:00:00\n",
            "Collecting spglm>=1.1.0 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/04/14/fac87dce2abbd7ee3b3bb3250cc2980388802f8cded9234d8ecb09801534/spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "Collecting spint>=1.0.7 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7e/c5/e4862ab3f745a1886135b07e498e77504c14e468d0a6b89f7270f5def979/spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting spreg>=1.8.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/14/59/c0163aa3071963201f183225554347697172d12045798be28a351b27ca95/spreg-1.8.3-py3-none-any.whl (389 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/ca/1b19058ece23148fed604d699e86c0edbd4909c7725749292f438e54e7cc/tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Collecting mapclassify>=2.8.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/e9/d7531a07454927788642373ae253ad6dd8714fec375a789031418ecebf2d/mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "Collecting splot>=1.1.7 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/c7/bc840c32ee973c4609465c1d8722f3e433653edf6aab65ba341cd59fcf34/splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Collecting spopt>=0.6.1 (from pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/59/08e1796f4dda22a780254ad24c525dd4641daee86a3f5212c807b4a55c4a/spopt-0.6.1-py3-none-any.whl (243 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from beautifulsoup4>=4.10->pysal>=2.6.0->commot) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from beautifulsoup4>=4.10->pysal>=2.6.0->commot) (4.14.1)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from geopandas>=0.10.0->pysal>=2.6.0->commot) (0.11.1)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from geopandas>=0.10.0->pysal>=2.6.0->commot) (3.7.1)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0c/33/07044ad6529c01ce4fac032d2124d2815ead529fb95eb6616aed8c0a57c1/quantecon-0.10.1-py3-none-any.whl (325 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from inequality>=1.1.1->pysal>=2.6.0->commot) (3.10.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=3 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal>=2.6.0->commot) (3.2.5)\n",
            "Requirement already satisfied: certifi in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from pyogrio>=0.7.2->geopandas>=0.10.0->pysal>=2.6.0->commot) (2025.7.14)\n",
            "Requirement already satisfied: numba>=0.49.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from quantecon>=0.7->giddy>=2.3.6->pysal>=2.6.0->commot) (0.62.1)\n",
            "Requirement already satisfied: sympy in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from quantecon>=0.7->giddy>=2.3.6->pysal>=2.6.0->commot) (1.14.0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from numba>=0.49.0->quantecon>=0.7->giddy>=2.3.6->pysal>=2.6.0->commot) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.27->pysal>=2.6.0->commot) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.27->pysal>=2.6.0->commot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from requests>=2.27->pysal>=2.6.0->commot) (1.26.20)\n",
            "Requirement already satisfied: joblib in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (1.5.1)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4.1 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (1.5)\n",
            "Requirement already satisfied: patsy!=1.0.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (1.0.2)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (0.5.13)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (0.13.2)\n",
            "Requirement already satisfied: session-info2 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (0.2.3)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (0.14.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scanpy>=1.8.2->commot) (0.5.9.post2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from scikit-learn>=1.0.2->commot) (3.6.0)\n",
            "Collecting deprecation (from segregation>=2.5.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: wrapt in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from smart_open>=1.8.1->gensim>=4.0.0->karateclub>=1.2.2->commot) (1.17.3)\n",
            "Requirement already satisfied: rtree>=1.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from spaghetti>=1.7.6->pysal>=2.6.0->commot) (1.4.0)\n",
            "Collecting pulp>=2.7 (from spopt>=0.6.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/99/6c/64cafaceea3f99927e84b38a362ec6a8f24f33061c90bda77dfe1cd4c3c6/pulp-3.3.0-py3-none-any.whl (16.4 MB)\n",
            "     ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.8/16.4 MB 3.7 MB/s eta 0:00:05\n",
            "     --- ------------------------------------ 1.6/16.4 MB 4.2 MB/s eta 0:00:04\n",
            "     ----- ---------------------------------- 2.4/16.4 MB 4.1 MB/s eta 0:00:04\n",
            "     ------- -------------------------------- 3.1/16.4 MB 3.8 MB/s eta 0:00:04\n",
            "     --------- ------------------------------ 3.9/16.4 MB 3.8 MB/s eta 0:00:04\n",
            "     ----------- ---------------------------- 4.7/16.4 MB 3.8 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 5.5/16.4 MB 3.7 MB/s eta 0:00:03\n",
            "     --------------- ------------------------ 6.3/16.4 MB 3.8 MB/s eta 0:00:03\n",
            "     ----------------- ---------------------- 7.1/16.4 MB 3.9 MB/s eta 0:00:03\n",
            "     ------------------- -------------------- 8.1/16.4 MB 3.9 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 8.9/16.4 MB 3.9 MB/s eta 0:00:02\n",
            "     ----------------------- ---------------- 9.7/16.4 MB 3.9 MB/s eta 0:00:02\n",
            "     -------------------------- ------------- 10.7/16.4 MB 3.9 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 11.8/16.4 MB 4.0 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 12.6/16.4 MB 4.0 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 13.4/16.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 14.4/16.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 15.2/16.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  16.0/16.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 16.4/16.4 MB 4.0 MB/s eta 0:00:00\n",
            "Collecting rasterio (from tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/51/2f/f72f77633aecba9afda903f9201c566520cc2dfeb0e1e0d36c102aa18189/rasterio-1.4.3-cp310-cp310-win_amd64.whl (25.4 MB)\n",
            "     ---------------------------------------- 0.0/25.4 MB ? eta -:--:--\n",
            "     - -------------------------------------- 1.0/25.4 MB 5.6 MB/s eta 0:00:05\n",
            "     -- ------------------------------------- 1.8/25.4 MB 4.8 MB/s eta 0:00:05\n",
            "     ---- ----------------------------------- 2.6/25.4 MB 4.6 MB/s eta 0:00:05\n",
            "     ----- ---------------------------------- 3.4/25.4 MB 4.4 MB/s eta 0:00:06\n",
            "     ------- -------------------------------- 4.5/25.4 MB 4.3 MB/s eta 0:00:05\n",
            "     -------- ------------------------------- 5.2/25.4 MB 4.2 MB/s eta 0:00:05\n",
            "     --------- ------------------------------ 5.8/25.4 MB 4.1 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 6.6/25.4 MB 3.9 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 7.6/25.4 MB 4.1 MB/s eta 0:00:05\n",
            "     ------------- -------------------------- 8.4/25.4 MB 4.1 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 9.4/25.4 MB 4.1 MB/s eta 0:00:04\n",
            "     ---------------- ----------------------- 10.2/25.4 MB 4.1 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 11.3/25.4 MB 4.2 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 12.1/25.4 MB 4.1 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 13.4/25.4 MB 4.2 MB/s eta 0:00:03\n",
            "     --------------------- ------------------ 13.9/25.4 MB 4.3 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 15.2/25.4 MB 4.2 MB/s eta 0:00:03\n",
            "     ------------------------- -------------- 16.0/25.4 MB 4.2 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 16.8/25.4 MB 4.2 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 17.6/25.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ---------------------------- ----------- 18.4/25.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 19.1/25.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 20.2/25.4 MB 4.2 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 21.0/25.4 MB 4.2 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 21.8/25.4 MB 4.2 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 22.5/25.4 MB 4.1 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 22.5/25.4 MB 4.1 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 23.3/25.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 24.1/25.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  24.9/25.4 MB 4.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 25.4/25.4 MB 3.9 MB/s eta 0:00:00\n",
            "Collecting rasterstats (from tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5e/0b/bd73621d2a5f87da97158c5c77a4bf31e27d60cf6bcc6ddea532043cc21d/rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: colorama in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from tqdm->karateclub>=1.2.2->commot) (0.4.6)\n",
            "Requirement already satisfied: zipp>=3.20 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from importlib-metadata->commot) (3.23.0)\n",
            "Collecting Levenshtein==0.27.3 (from python-Levenshtein->karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/15/50f508790a7b7e0d6258ec85add62c257ab27ca70e5e8a1bae8350305932/levenshtein-0.27.3-cp310-cp310-win_amd64.whl (94 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-Levenshtein->karateclub>=1.2.2->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/09/6b/64ad573337d81d64bc78a6a1df53a72a71d54d43d276ce0662c2e95a1f35/rapidfuzz-3.14.3-cp310-cp310-win_amd64.whl (1.5 MB)\n",
            "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "     ------------- -------------------------- 0.5/1.5 MB 3.4 MB/s eta 0:00:01\n",
            "     --------------------------------- ------ 1.3/1.5 MB 2.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.5/1.5 MB 2.8 MB/s eta 0:00:00\n",
            "Collecting affine (from rasterio->tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/f7/85273299ab57117850cc0a936c64151171fac4da49bc6fba0dad984a7c5f/affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from rasterio->tobler>=0.12.1->pysal>=2.6.0->commot) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from rasterio->tobler>=0.12.1->pysal>=2.6.0->commot) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio->tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/73/86/43fa9f15c5b9fb6e82620428827cd3c284aa933431405d1bcf5231ae3d3e/cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting click-plugins (from rasterio->tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3d/9a/2abecb28ae875e39c8cad711eb1186d8d14eab564705325e77e4e6ab9ae5/click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting fiona (from rasterstats->tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/a3/57d33c2f16a2a6b27911d83301a697ed1491dca48d2f1dd2ed3b58a66244/fiona-1.10.1-cp310-cp310-win_amd64.whl (24.5 MB)\n",
            "     ---------------------------------------- 0.0/24.5 MB ? eta -:--:--\n",
            "      --------------------------------------- 0.5/24.5 MB 3.4 MB/s eta 0:00:08\n",
            "     -- ------------------------------------- 1.3/24.5 MB 3.5 MB/s eta 0:00:07\n",
            "     --- ------------------------------------ 2.1/24.5 MB 3.7 MB/s eta 0:00:07\n",
            "     ---- ----------------------------------- 2.9/24.5 MB 3.6 MB/s eta 0:00:07\n",
            "     ----- ---------------------------------- 3.7/24.5 MB 3.8 MB/s eta 0:00:06\n",
            "     ------- -------------------------------- 4.7/24.5 MB 3.9 MB/s eta 0:00:06\n",
            "     -------- ------------------------------- 5.5/24.5 MB 3.9 MB/s eta 0:00:05\n",
            "     ---------- ----------------------------- 6.6/24.5 MB 4.0 MB/s eta 0:00:05\n",
            "     ----------- ---------------------------- 7.3/24.5 MB 4.0 MB/s eta 0:00:05\n",
            "     ------------ --------------------------- 7.9/24.5 MB 4.0 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 8.7/24.5 MB 3.9 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 9.7/24.5 MB 3.9 MB/s eta 0:00:04\n",
            "     ----------------- ---------------------- 10.7/24.5 MB 4.0 MB/s eta 0:00:04\n",
            "     ------------------ --------------------- 11.5/24.5 MB 4.0 MB/s eta 0:00:04\n",
            "     -------------------- ------------------- 12.3/24.5 MB 4.0 MB/s eta 0:00:04\n",
            "     --------------------- ------------------ 13.1/24.5 MB 4.0 MB/s eta 0:00:03\n",
            "     ----------------------- ---------------- 14.2/24.5 MB 4.0 MB/s eta 0:00:03\n",
            "     ------------------------ --------------- 14.9/24.5 MB 4.0 MB/s eta 0:00:03\n",
            "     -------------------------- ------------- 16.0/24.5 MB 4.0 MB/s eta 0:00:03\n",
            "     --------------------------- ------------ 16.8/24.5 MB 4.1 MB/s eta 0:00:02\n",
            "     ----------------------------- ---------- 17.8/24.5 MB 4.1 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 18.6/24.5 MB 4.1 MB/s eta 0:00:02\n",
            "     ------------------------------ --------- 18.9/24.5 MB 4.1 MB/s eta 0:00:02\n",
            "     ------------------------------- -------- 19.4/24.5 MB 3.9 MB/s eta 0:00:02\n",
            "     -------------------------------- ------- 20.2/24.5 MB 3.9 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 21.0/24.5 MB 3.9 MB/s eta 0:00:01\n",
            "     ----------------------------------- ---- 21.5/24.5 MB 3.8 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 22.3/24.5 MB 3.8 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 22.8/24.5 MB 3.8 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 23.6/24.5 MB 3.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  24.4/24.5 MB 3.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 24.5/24.5 MB 3.7 MB/s eta 0:00:00\n",
            "Collecting simplejson (from rasterstats->tobler>=0.12.1->pysal>=2.6.0->commot)\n",
            "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ad/87/a6e03d4d80cca99c1fee4e960f3440e2f21be9470e537970f960ca5547f1/simplejson-3.20.2-cp310-cp310-win_amd64.whl (76 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\www\\xxx\\game\\anaconda\\envs\\crawl4ai\\lib\\site-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal>=2.6.0->commot) (1.3.0)\n",
            "Building wheels for collected packages: karateclub, python-louvain, spint\n",
            "  Building wheel for karateclub (setup.py): started\n",
            "  Building wheel for karateclub (setup.py): finished with status 'done'\n",
            "  Created wheel for karateclub: filename=karateclub-1.2.2-py3-none-any.whl size=97810 sha256=c19da3a3b47400b94566f4056c720e5ac258729ff2c3391fe9b56571173ff364\n",
            "  Stored in directory: c:\\users\\86152\\appdata\\local\\pip\\cache\\wheels\\92\\f8\\f8\\3c8a477a27653d6c8d149ac0b5e98e405c366b6d17a5dd6217\n",
            "  Building wheel for python-louvain (setup.py): started\n",
            "  Building wheel for python-louvain (setup.py): finished with status 'done'\n",
            "  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9473 sha256=1e8ec2cfcd530f178f1a88ff0cbaaa11f2d354c5e22b81e5afe3d1d88a3b79a6\n",
            "  Stored in directory: c:\\users\\86152\\appdata\\local\\pip\\cache\\wheels\\6b\\f3\\22\\7c2d1a98d4b89588f0570fcb5e608399db1256a796e14239f0\n",
            "  Building wheel for spint (setup.py): started\n",
            "  Building wheel for spint (setup.py): finished with status 'done'\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31456 sha256=4f78d0070e5e625d15700f7ff0d2eeff43b9cf252b28864f4a328bc6afcf6d32\n",
            "  Stored in directory: c:\\users\\86152\\appdata\\local\\pip\\cache\\wheels\\4e\\2d\\d6\\bc4ccc4d2469db3a6b06f587e9b543a85cd80e871fbd616661\n",
            "Successfully built karateclub python-louvain spint\n",
            "Installing collected packages: texttable, smart_open, simplejson, rapidfuzz, python-louvain, pulp, narwhals, igraph, deprecation, decorator, affine, quantecon, python-igraph, pygsp, pot, plotly, Levenshtein, leidenalg, gensim, cligj, click-plugins, rasterio, python-Levenshtein, mapclassify, fiona, rasterstats, libpysal, karateclub, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal, commot\n",
            "\n",
            "    ---------------------------------------  1/45 [smart_open]\n",
            "    ---------------------------------------  1/45 [smart_open]\n",
            "   - --------------------------------------  2/45 [simplejson]\n",
            "   - --------------------------------------  2/45 [simplejson]\n",
            "   - --------------------------------------  2/45 [simplejson]\n",
            "   - --------------------------------------  2/45 [simplejson]\n",
            "   -- -------------------------------------  3/45 [rapidfuzz]\n",
            "   -- -------------------------------------  3/45 [rapidfuzz]\n",
            "   -- -------------------------------------  3/45 [rapidfuzz]\n",
            "   --- ------------------------------------  4/45 [python-louvain]\n",
            "   ---- -----------------------------------  5/45 [pulp]\n",
            "   ---- -----------------------------------  5/45 [pulp]\n",
            "   ---- -----------------------------------  5/45 [pulp]\n",
            "   ---- -----------------------------------  5/45 [pulp]\n",
            "   ---- -----------------------------------  5/45 [pulp]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ----- ----------------------------------  6/45 [narwhals]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------ ---------------------------------  7/45 [igraph]\n",
            "   ------- --------------------------------  8/45 [deprecation]\n",
            "  Attempting uninstall: decorator\n",
            "   ------- --------------------------------  8/45 [deprecation]\n",
            "    Found existing installation: decorator 5.2.1\n",
            "   ------- --------------------------------  8/45 [deprecation]\n",
            "    Uninstalling decorator-5.2.1:\n",
            "   ------- --------------------------------  8/45 [deprecation]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "      Successfully uninstalled decorator-5.2.1\n",
            "   -------- -------------------------------  9/45 [decorator]\n",
            "   -------- ------------------------------- 10/45 [affine]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   --------- ------------------------------ 11/45 [quantecon]\n",
            "   ---------- ----------------------------- 12/45 [python-igraph]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ----------- ---------------------------- 13/45 [pygsp]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------ --------------------------- 14/45 [pot]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   ------------- -------------------------- 15/45 [plotly]\n",
            "   --------------- ------------------------ 17/45 [leidenalg]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 18/45 [gensim]\n",
            "   ---------------- ----------------------- 19/45 [cligj]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   ------------------ --------------------- 21/45 [rasterio]\n",
            "   -------------------- ------------------- 23/45 [mapclassify]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   --------------------- ------------------ 24/45 [fiona]\n",
            "   ---------------------- ----------------- 25/45 [rasterstats]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ----------------------- ---------------- 26/45 [libpysal]\n",
            "   ------------------------ --------------- 27/45 [karateclub]\n",
            "   ------------------------ --------------- 27/45 [karateclub]\n",
            "   ------------------------ --------------- 27/45 [karateclub]\n",
            "   ------------------------ --------------- 27/45 [karateclub]\n",
            "   ------------------------ --------------- 28/45 [access]\n",
            "   ------------------------- -------------- 29/45 [tobler]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   -------------------------- ------------- 30/45 [spreg]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   --------------------------- ------------ 31/45 [segregation]\n",
            "   ---------------------------- ----------- 32/45 [pointpats]\n",
            "   ---------------------------- ----------- 32/45 [pointpats]\n",
            "   ----------------------------- ---------- 33/45 [momepy]\n",
            "   ----------------------------- ---------- 33/45 [momepy]\n",
            "   ----------------------------- ---------- 33/45 [momepy]\n",
            "   ----------------------------- ---------- 33/45 [momepy]\n",
            "   ------------------------------ --------- 34/45 [inequality]\n",
            "   ------------------------------ --------- 34/45 [inequality]\n",
            "   ------------------------------- -------- 35/45 [esda]\n",
            "   ------------------------------- -------- 35/45 [esda]\n",
            "   ------------------------------- -------- 35/45 [esda]\n",
            "   ------------------------------- -------- 35/45 [esda]\n",
            "   -------------------------------- ------- 36/45 [spglm]\n",
            "   -------------------------------- ------- 37/45 [spaghetti]\n",
            "   --------------------------------- ------ 38/45 [giddy]\n",
            "   --------------------------------- ------ 38/45 [giddy]\n",
            "   ---------------------------------- ----- 39/45 [spopt]\n",
            "   ---------------------------------- ----- 39/45 [spopt]\n",
            "   ---------------------------------- ----- 39/45 [spopt]\n",
            "   ---------------------------------- ----- 39/45 [spopt]\n",
            "   ----------------------------------- ---- 40/45 [splot]\n",
            "   ----------------------------------- ---- 40/45 [splot]\n",
            "   ------------------------------------ --- 41/45 [spint]\n",
            "   ------------------------------------- -- 42/45 [mgwr]\n",
            "   -------------------------------------- - 43/45 [pysal]\n",
            "   -------------------------------------- - 43/45 [pysal]\n",
            "   ---------------------------------------  44/45 [commot]\n",
            "   ---------------------------------------  44/45 [commot]\n",
            "   ---------------------------------------- 45/45 [commot]\n",
            "\n",
            "Successfully installed Levenshtein-0.27.3 access-1.1.9 affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 commot-0.0.3 decorator-4.4.2 deprecation-2.1.0 esda-2.7.0 fiona-1.10.1 gensim-4.4.0 giddy-2.3.6 igraph-1.0.0 inequality-1.1.1 karateclub-1.2.2 leidenalg-0.11.0 libpysal-4.13.0 mapclassify-2.8.1 mgwr-2.2.1 momepy-0.9.1 narwhals-2.12.0 plotly-6.5.0 pointpats-2.5.2 pot-0.9.6.post1 pulp-3.3.0 pygsp-0.6.1 pysal-25.1 python-Levenshtein-0.27.3 python-igraph-1.0.0 python-louvain-0.16 quantecon-0.10.1 rapidfuzz-3.14.3 rasterio-1.4.3 rasterstats-0.20.0 segregation-2.5.2 simplejson-3.20.2 smart_open-7.5.0 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.6.1 spreg-1.8.3 texttable-1.7.0 tobler-0.12.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: Building 'karateclub' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'karateclub'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "  DEPRECATION: Building 'python-louvain' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'python-louvain'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
            "  DEPRECATION: Building 'spint' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'spint'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
          ]
        }
      ],
      "source": [
        "!pip install commot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eEtFcg4SfD8F",
      "metadata": {
        "id": "eEtFcg4SfD8F"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e405fec5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import synapseclient\n",
        "from synapseclient import Synapse\n",
        "import gcsfs\n",
        "\n",
        "import vertexai\n",
        "import requests\n",
        "from vertexai.preview import reasoning_engines\n",
        "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
        "\n",
        "import scanpy as sc\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ex1_NzVnZXSp",
      "metadata": {
        "id": "ex1_NzVnZXSp"
      },
      "outputs": [],
      "source": [
        "import pandas_gbq\n",
        "\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "syn = synapseclient.login(authToken=\"\", silent=True)\n",
        "\n",
        "\n",
        "os.environ['SYNAPSE_AUTH_TOKEN'] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YxPLHy1carkI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "executionInfo": {
          "elapsed": 1015,
          "status": "ok",
          "timestamp": 1731078327815,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "YxPLHy1carkI",
        "outputId": "90f1b693-5040-446b-8801-c2eae8a6a5fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b92bd6d4-5d2b-4f25-bb52-7534c173fbf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attribute:</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Filename:</td>\n",
              "      <td>Name of a file</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run ID:</td>\n",
              "      <td>A unique identifier for this individual run (t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>File Format:</td>\n",
              "      <td>Format of a file (e.g. txt, csv, fastq, bam, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HTAN Parent Biospecimen ID:</td>\n",
              "      <td>HTAN Biospecimen Identifier (eg HTANx_yyy_zzz)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HTAN Data File ID:</td>\n",
              "      <td>Self-identifier for this data file - HTAN ID o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92bd6d4-5d2b-4f25-bb52-7534c173fbf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b92bd6d4-5d2b-4f25-bb52-7534c173fbf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b92bd6d4-5d2b-4f25-bb52-7534c173fbf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-978bcb56-7593-4c60-8870-dcb5751342d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-978bcb56-7593-4c60-8870-dcb5751342d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-978bcb56-7593-4c60-8870-dcb5751342d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                    Attribute:  \\\n",
              "0                    Filename:   \n",
              "1                      Run ID:   \n",
              "2                 File Format:   \n",
              "3  HTAN Parent Biospecimen ID:   \n",
              "4           HTAN Data File ID:   \n",
              "\n",
              "                                         Description  \n",
              "0                                     Name of a file  \n",
              "1  A unique identifier for this individual run (t...  \n",
              "2  Format of a file (e.g. txt, csv, fastq, bam, e...  \n",
              "3  HTAN Biospecimen Identifier (eg HTANx_yyy_zzz)...  \n",
              "4  Self-identifier for this data file - HTAN ID o...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to your GCS file\n",
        "file_path = 'gs://htan_st_datasets/HTAN_ST_metadata_ad.tsv'\n",
        "\n",
        "# Create a GCS filesystem object\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "# Load the TSV file directly from GCS\n",
        "with fs.open(file_path) as f:\n",
        "    metadata_df = pd.read_csv(f, sep='\\t')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "metadata_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WSPknVyiasPo",
      "metadata": {
        "id": "WSPknVyiasPo"
      },
      "source": [
        "# ChatVertexAI Multi-agent LLM Using LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2OpIWxZCd9_A",
      "metadata": {
        "id": "2OpIWxZCd9_A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x000002048A7895A0> (for pre_run_cell), with arguments args (<ExecutionInfo object at 2048a9d4640, raw_cell=\"\n",
            "from contextlib import redirect_stdout\n",
            "\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/d%3A/VT/HTAN_dataset/HTANalyzer-LLM/demo_app_with_super_agent.ipynb#X13sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;31mTypeError\u001b[0m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "\n",
        "from contextlib import redirect_stdout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-kn6Mtcacpb7",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "executionInfo": {
          "elapsed": 2766,
          "status": "ok",
          "timestamp": 1731090744630,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "-kn6Mtcacpb7",
        "outputId": "53889180-09bc-428e-b111-4dbfe9932be1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## %%capture captured_output\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
        "\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "from typing import TypedDict, Annotated,Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain.agents.output_parsers.tools import ToolAgentAction\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "vertexai.init(\n",
        "    project=\"isb-cgc-external-004\",\n",
        "    location=\"us-central1\",\n",
        "    staging_bucket=\"gs://htan_st_datasets/staging_dir/\",\n",
        ")\n",
        "\n",
        "model = \"gemini-1.5-flash-002\"\n",
        "\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "}\n",
        "\n",
        "model_kwargs = {\n",
        "    # temperature (float): The sampling temperature controls the degree of\n",
        "    # randomness in token selection.\n",
        "    \"temperature\": 0.28,\n",
        "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
        "    # text output from one prompt.\n",
        "    \"max_output_tokens\": 8000,\n",
        "    # top_p (float): Tokens are selected from most probable to least until\n",
        "    # the sum of their probabilities equals the top-p value.\n",
        "    \"top_p\": 0.95,\n",
        "    # top_k (int): The next token is selected from among the top-k most\n",
        "    # probable tokens.\n",
        "    \"top_k\": 40,\n",
        "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
        "    # settings to use for generating content.\n",
        "    \"safety_settings\": safety_settings,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "]\n",
        "\n",
        "@tool\n",
        "def agent_1(question: str) -> str:\n",
        "    \"\"\"\n",
        "   Download files from HTAN or Synapse. You can directly download files by generating and executing Python code to retrieve datasets using APIs.\n",
        "\n",
        "    Parameters:\n",
        "    question (str): A user-defined question regarding dataset retrieval from HTAN or Synapse.\n",
        "\n",
        "    Returns:\n",
        "    str: Python code enclosed in ```python``` tags, allowing the user to easily extract the code.\n",
        "         Code will be specific to either BigQuery for HTAN datasets or synapseclient for Synapse datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in downloading datasets from Human Tumor Network Atlas (HTAN) and Synapse using APIs. You can directly download files. Return only the python code.\n",
        "\n",
        "    For Synapse Datasets:\n",
        "    You can write the Python code to download the Synapse data directly using the synapseclient by passing the synapse id and the download location. If the download location is not defined, download to ./. You can login using synapseclient.login(silent=True) function.\n",
        "\n",
        "    For Datasets with an HTAN biospecimen ID:\n",
        "    You can use BigQuery in Google Cloud to do this. Assume that all the packages are already installed. You can use: project_id = \"isb-cgc-external-004\".\n",
        "\n",
        "    Important considerations:\n",
        "\n",
        "    1. Please write and execute the Python code enclosed in ```python``` tags so that the user can regex extract the code easily.\n",
        "\n",
        "    2. You do not have to access any data. You are an expert coder, just write the code. When you're asked to load a dataset, use BigQuery to load it.\n",
        "\n",
        "    3. Include all the necessary import packages to run the code. If using any Google Cloud services, you can use:\n",
        "    project_id = \"isb-cgc-external-004\"\n",
        "\n",
        "    4. Do not write any try except blocks.\n",
        "\n",
        "    Make sure you follow the considerations.\n",
        "\n",
        "    Here are some examples:\n",
        "\n",
        "    Question: Can you load the cells from the HTAN biospecimen HTA7_1_3?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    WITH cells AS (\n",
        "      SELECT  CellID, X_centroid, Y_centroid,\n",
        "      FROM `isb-cgc-bq.HTAN.imaging_level4_HMS_mel_mask_current`\n",
        "      WHERE HTAN_Biospecimen_ID = 'HTA7_1_3'\n",
        "    )\n",
        "    SELECT CellID, X_centroid,  Y_centroid\n",
        "    FROM cells\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    #### Synapse data download : Example 1\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Question: Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current\n",
        "    where the File_Format is hdf5?\n",
        "\n",
        "    Answer:\n",
        "    '''\n",
        "    import pandas_gbq\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    project_id = \"isb-cgc-external-004\"\n",
        "\n",
        "    query = '''\n",
        "    SELECT entityId\n",
        "    FROM `isb-cgc-bq.HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current`\n",
        "    WHERE File_Format = 'hdf5'\n",
        "    '''\n",
        "\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ##  Synapse example 2\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Question: Can you download the synapse data 'syn51133602' to /content/datasets/?\n",
        "    Answer:\n",
        "    '''\n",
        "    import synapseclient\n",
        "    syn = synapseclient.login(silent=True)\n",
        "    entity = syn.get('syn51133602', downloadLocation='/content/datasets')\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### Spatial example 1\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Question: Can you categorize cells within a defined spatial region as either 'Tumor' or 'Other' based on threshold expression levels of specific markers (SOX10_cellRingMask, S100B_cellRingMask, and CD63_cellRingMask)?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "      WITH cells AS (\n",
        "      SELECT CellID, X_centroid, Y_centroid,\n",
        "      IF (SOX10_cellRingMask > 3704.5 AND (S100B_cellRingMask > 7589.48 OR CD63_cellRingMask > 570.68),\n",
        "      'Tumor', 'Other') AS celltype\n",
        "      FROM `isb-cgc-bq.HTAN.imaging_level4_HMS_mel_mask_current`\n",
        "      WHERE HTAN_Biospecimen_ID = 'HTA7_1_3')\n",
        "\n",
        "      SELECT CellID, X_centroid, Y_centroid, celltype\n",
        "      FROM cells\n",
        "      WHERE X_centroid > 23076.9 AND X_centroid < 30384.6\n",
        "      AND Y_centroid > 9615.3 AND Y_centroid < 15000\n",
        "      '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    \"\"\"\n",
        "\n",
        "    ### Spatial example 2\n",
        "    prompt += f\"\"\"\n",
        "    Question: Can you classify cells as 'Tumor' or 'Other', convert their pixel coordinates to geospatial points, and calculate distances between cell pairs that are within a 20-micrometer proximity threshold\n",
        "    Answer:\n",
        "    query = '''\n",
        "      WITH geodat AS (\n",
        "      SELECT CellID, X_centroid, Y_centroid,\n",
        "      IF (SOX10_cellRingMask > 3704.5 AND (S100B_cellRingMask > 7589.48 OR CD63_cellRingMask > 570.68),\n",
        "      'Tumor', 'Other') AS celltype,\n",
        "      ST_GeogPoint(X_centroid / 368570, Y_centroid / 368570) AS p\n",
        "      FROM `isb-cgc-bq.HTAN.imaging_level4_HMS_mel_mask_current`\n",
        "      WHERE HTAN_Biospecimen_ID = 'HTA7_1_3'\n",
        "      )\n",
        "    SELECT t1.CellID, t1.X_centroid, t1.Y_centroid, t1.p, t1.celltype,\n",
        "    t2.CellID AS CellID_1, t2.X_centroid AS X_centroid_1, t2.Y_centroid AS Y_centroid_1, t2.p AS p_1, t2.celltype AS celltype_1,\n",
        "    ST_Distance(t1.p, t2.p) AS Distance\n",
        "    FROM geodat AS t1\n",
        "    JOIN geodat AS t2\n",
        "    ON ST_DWithin(t1.p, t2.p, 9.29324770787722)\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### Spatial example 3\n",
        "    prompt += f\"\"\"\n",
        "    Question: For each tumor cell within the specified spatial region, calculate the number of neighboring tumor cells\n",
        "    Answer:\n",
        "    query = '''\n",
        "      WITH cellp AS (\n",
        "      SELECT CellID, celltype, CellID_1, celltype_1\n",
        "      FROM `isb-cgc-bq.temp15432.Melanoma_CyCIF_HTA7_1_3_points_within_20um`\n",
        "      WHERE X_centroid > 23076.9 AND X_centroid < 30384.6\n",
        "      AND Y_centroid > 9615.3 AND Y_centroid < 15000)\n",
        "\n",
        "      SELECT CellID, COUNTIF(celltype_1 = 'Tumor') - 1 AS N_Tumor_Cells\n",
        "      FROM cellp\n",
        "      WHERE celltype = 'Tumor'\n",
        "      GROUP BY CellID\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ## Metadata\n",
        "\n",
        "    # Create a prompt with the file content included\n",
        "    prompt += f\"\"\"\n",
        "    The HTAN metadata contains a subset of these type of attributes. Also included is a description of these attributes. Internalize this information and use it to answer any queries related to metadata.\n",
        "\n",
        "    Metadata Description:\n",
        "    {metadata_df}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    ## ScRNAseq example 1\n",
        "    prompt += f\"\"\"\n",
        "    Question: What are the counts of unique cells, sex groupings, samples,\n",
        "    cell types, and therapies by development stage in the MSK scRNAseq dataset?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT\n",
        "      development_stage,\n",
        "      count(distinct(iObs)) AS Number_Cells,\n",
        "      count(distinct(sex)) AS Unique_Sex_Grouping,\n",
        "      count(distinct(donor_id)) AS Number_Samples,\n",
        "      count(distinct(cell_type)) AS Number_Cell_Types,\n",
        "      count(distinct(treatment)) AS Number_Therapies\n",
        "    FROM\n",
        "      `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "    GROUP BY development_stage\n",
        "    ORDER BY Number_Samples DESC\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ## ScRNAseq example 2\n",
        "    prompt += f\"\"\"\n",
        "    Question: How many unique cell types, sex groupings, cells, and samples\n",
        "    are present in the a specific human stage of development in the MSK\n",
        "    scRNAseq dataset (e.g. 74-year-old)?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT\n",
        "      cell_type,\n",
        "      count(distinct(sex)) AS Unique_Sex_Grouping,\n",
        "      count(distinct(iObs)) AS Number_Cells,\n",
        "      count(distinct(donor_id)) AS Number_Samples\n",
        "    FROM\n",
        "      `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "    WHERE\n",
        "      development_stage = '74-year-old human stage'\n",
        "    GROUP BY cell_type\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ## ScRNAseq example 3\n",
        "    prompt += f\"\"\"\n",
        "    Question: How many genes and cells are associated with each sex and\n",
        "    cell type in the MSK scRNAseq dataset for an individual\n",
        "    (e.g. a 74-year-old human stage)?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT\n",
        "      sex,\n",
        "      Cell_Type,\n",
        "      count(distinct(feature_name)) AS Number_Genes,\n",
        "      count(distinct(iObs)) AS Number_Cells\n",
        "    FROM\n",
        "      `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "    WHERE development_stage = '74-year-old human stage'\n",
        "    GROUP BY sex, Cell_Type\n",
        "    ORDER BY Cell_Type DESC\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ## ScRNAseq example 4\n",
        "    prompt += f\"\"\"\n",
        "    Question: How many genes and cells are there in each Seurat Cluster\n",
        "    for males and females of the 'epithelial cell' type in the specific\n",
        "    human stage (here 74-year-old)?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT\n",
        "      sex,\n",
        "      clusters,\n",
        "      Cell_Type,\n",
        "      count(distinct(feature_name)) AS Number_Genes,\n",
        "      count(distinct(iObs)) AS Number_Cells\n",
        "    FROM\n",
        "      `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "    WHERE development_stage = '74-year-old human stage' AND Cell_Type = 'epithelial cell'\n",
        "    GROUP BY sex, clusters, Cell_Type\n",
        "    ORDER BY clusters ASC\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "   ## ScRNAseq example 5\n",
        "    prompt += f\"\"\"\n",
        "    Question: How do the average expression values for genes differ between\n",
        "    male and female epithelial cells in a specific cluster, and which genes\n",
        "    show the greatest differences (here cluster 41 of the 74-year-old\n",
        "    human stage)?\n",
        "    Answer:\n",
        "    '''\n",
        "    query = '''\n",
        "    SELECT\n",
        "      A.feature_name,\n",
        "      A.avg_counts_clust10 AS female_avg_counts,\n",
        "      B.avg_counts_clust10 AS male_avg_counts,\n",
        "      A.avg_counts_clust10 - B.avg_counts_clust10 AS mean_diff\n",
        "    FROM (\n",
        "      SELECT\n",
        "        feature_name,\n",
        "        AVG(X_value) AS avg_counts_clust10\n",
        "      FROM\n",
        "        `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "      WHERE development_stage = '74-year-old human stage' AND Cell_Type = 'epithelial cell' AND clusters = '41' AND sex = 'female'\n",
        "      GROUP BY feature_name\n",
        "    ) AS A\n",
        "    INNER JOIN (\n",
        "      SELECT\n",
        "        feature_name,\n",
        "        AVG(X_value) AS avg_counts_clust10\n",
        "      FROM\n",
        "        `isb-cgc-bq.HTAN.scRNAseq_MSK_SCLC_combined_samples_current`\n",
        "      WHERE development_stage = '74-year-old human stage' AND Cell_Type = 'epithelial cell' AND clusters = '41' AND sex = 'male'\n",
        "      GROUP BY feature_name\n",
        "    ) AS B\n",
        "    ON A.feature_name = B.feature_name\n",
        "    ORDER BY mean_diff DESC\n",
        "    '''\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "    '''\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Add the dynamic user question and the placeholder for the answer\n",
        "    prompt += f\"\"\"\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    vertexai.init(project=\"isb-cgc-external-004\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-flash-002\",\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "        # tools='code_execution'\n",
        "    )\n",
        "\n",
        "    # for response in responses:\n",
        "    #     print(response.text, end=\"\")\n",
        "\n",
        "    pattern = r'```python\\n(.*?)\\n```'\n",
        "\n",
        "    # Extract the code\n",
        "    match = re.search(pattern, responses.text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        python_code = match.group(1).strip()\n",
        "        print(python_code)\n",
        "        exec(python_code)\n",
        "\n",
        "    else:\n",
        "        print(\"Agent 1: Executed Python code.\")\n",
        "\n",
        "@tool\n",
        "def agent_2(question:str) -> str:\n",
        "    \"\"\"\n",
        "    Generate and execute Python code to query metadata or retrieve datasets from HTAN via Google Cloud\n",
        "    using BigQuery and relevant Python packages.\n",
        "\n",
        "    Parameters:\n",
        "    question (str): A user-defined question regarding metadata or dataset retrieval from HTAN.\n",
        "\n",
        "    Returns:\n",
        "    str: Python code enclosed in ```python``` tags for easy extraction. The code may include\n",
        "         BigQuery queries or use of libraries like pandas, scanpy, or squidpy depending on\n",
        "         the question.\n",
        "\n",
        "    Notes:\n",
        "    - Uses Google BigQuery with project ID 'isb-cgc-external-004' to access HTAN datasets.\n",
        "    - Responds to general questions with a conversational response if code is not required.\n",
        "    - Packages are imported as needed in the generated code.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a bioinformatics expert coder using the Human Tumor Network Atlas (HTAN) datasets via Google Cloud and Jupyter.\n",
        "    You can write Python code to answer questions by writing BigQuery queries, pandas, scanpy, squidpy, and commot code.\n",
        "    You have access to an AnnData object named 'adata' that contains:\n",
        "    - Gene expression data in adata.X\n",
        "    - Cell metadata in adata.obs, including 'kmeans_9_clusters' for cell types\n",
        "    - Gene names in adata.var_names\n",
        "    - Spatial coordinates in adata.obsm['spatial'] if available\n",
        "\n",
        "    Important technical details:\n",
        "    - Gene expression data is stored as a sparse matrix and needs to be converted using .toarray() or scipy.sparse methods\n",
        "    - Always handle sparse matrices appropriately\n",
        "    - Add clear comments explaining the analysis steps\n",
        "    - Include proper error handling for missing genes or data\n",
        "    - Use sc.pl.spatial() for spatial plots\n",
        "    - Use only 'cmap' parameter (not color_map) for color mapping\n",
        "    - Include proper error handling for missing coordinates or genes\n",
        "    - For multiple plots, use ncols parameter to arrange them\n",
        "    - Add clear comments explaining the analysis steps\n",
        "    - VERY IMPORTANT: Include all the necessary import packages to run the code.\n",
        "\n",
        "    For any commands that have the parameter 'database_name' or 'database' please use 'CellChat'.\n",
        "    The following results are attached after running ct.tl.spatial_communication. Please note that 'Fgf1-Fgfr1' can be replaced wiht other ligand-receptor pairs:\n",
        "    - adata.uns['commot-user_database-info']: Ligand-receptor database used.\n",
        "    - adata.obsm['commot-user_database-sum-sender']: Total sent signals per LR pair and pathway.\n",
        "    - adata.obsm['commot-user_database-sum-receiver']: Total received signals per LR pair and pathway.\n",
        "    - adata.obsm['commot_sender_vf-user_database-Fgf1-Fgfr1']: Signaling directions for sent signals.\n",
        "    - adata.obsm['commot_receiver_vf-user_database-Fgf1-Fgfr1']: Signaling directions for received signals.\n",
        "    - adata.obsp['commot-user_database-Fgf1-Fgfr1']: Sparse matrix of cell-cell communication scores per spot.\n",
        "\n",
        "    When responding to questions:\n",
        "    1. Analyze what type of operation is being requested\n",
        "    2. Generate appropriate Python code using scanpy, pandas, matplotlib, and other relevant libraries\n",
        "    3. For questions that require code, return ONLY the Python code within ```python``` tags\n",
        "    4. Include proper error handling and data validation\n",
        "    5. Add clear comments explaining the analysis steps\n",
        "\n",
        "    Examples of queries and their answers:\n",
        "\n",
        "    Question: How do preprocess my adata object?\n",
        "    Answer:\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from scipy import sparse\n",
        "    import matplotlib.pyplot as plt\n",
        "    sc.pp.normalize_total(adata, inplace=True)\n",
        "    sc.pp.log1p(adata)\n",
        "    '''\n",
        "\n",
        "    Q: \"Show me the distribution of cells across kmeans_9_clusters\"\n",
        "    A: ```python\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Get cluster counts\n",
        "    cluster_counts = adata.obs['kmeans_9_clusters'].value_counts().sort_index()\n",
        "\n",
        "    # Create bar plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    cluster_counts.plot(kind='bar')\n",
        "    plt.title('Distribution of Cells Across kmeans_9_clusters')\n",
        "    plt.xlabel('Cluster')\n",
        "    plt.ylabel('Number of Cells')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print numerical summary\n",
        "    print(\"\\\\nNumerical distribution:\")\n",
        "    print(pd.DataFrame({{\n",
        "        'Cluster': cluster_counts.index,\n",
        "        'Count': cluster_counts.values,\n",
        "        'Percentage': (cluster_counts.values / len(adata) * 100).round(2)\n",
        "    }}))\n",
        "    ```\n",
        "\n",
        "    Q: \"Find and plot the top 5 genes with highest Moran's I values\"\n",
        "    A: ```python\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    import scanpy as sc\n",
        "\n",
        "    # Create DataFrame with Moran's I statistics\n",
        "    morans_df = pd.DataFrame({{\n",
        "        'Gene': adata.var_names,\n",
        "        'Morans_I': adata.var['Morans_I'],\n",
        "        'Adj_P_Value': adata.var['Morans_I_adj_p_val']\n",
        "    }})\n",
        "\n",
        "    # Sort by Moran's I value and get top 5\n",
        "    top_genes = morans_df.sort_values('Morans_I', ascending=False).head(5)\n",
        "\n",
        "    # Create spatial plots for top genes\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Plot each gene\n",
        "    for idx, (gene, mi_value) in enumerate(zip(top_genes['Gene'], top_genes['Morans_I'])):\n",
        "        sc.pl.spatial(adata,\n",
        "                     color=gene,\n",
        "                     title=f'{{gene}}\\\\nMoran\\\\'s I = {{mi_value:.3f}}',\n",
        "                     ax=axes[idx],\n",
        "                     show=False,\n",
        "                     cmap='viridis')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary table\n",
        "    print(\"\\\\nTop 5 spatially autocorrelated genes:\")\n",
        "    print(top_genes)\n",
        "    ```\n",
        "\n",
        "    Q: \"Generate a UMAP visualization comparing kmeans_9_clusters with kmeans_10_clusters\"\n",
        "    A: ```python\n",
        "    import scanpy as sc\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Compute UMAP if not already present\n",
        "    if 'X_umap' not in adata.obsm_keys():\n",
        "        sc.pp.neighbors(adata, n_pcs=30)\n",
        "        sc.tl.umap(adata)\n",
        "\n",
        "    # Create subplot with both clustering results\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Plot UMAP with kmeans_9_clusters\n",
        "    sc.pl.umap(adata,\n",
        "               color='kmeans_9_clusters',\n",
        "               title='kmeans_9_clusters',\n",
        "               ax=ax1,\n",
        "               show=False)\n",
        "\n",
        "    # Plot UMAP with kmeans_10_clusters\n",
        "    sc.pl.umap(adata,\n",
        "               color='kmeans_10_clusters',\n",
        "               title='kmeans_10_clusters',\n",
        "               ax=ax2,\n",
        "               show=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print cluster sizes\n",
        "    print(\"\\\\nkmeans_9_clusters distribution:\")\n",
        "    print(adata.obs['kmeans_9_clusters'].value_counts())\n",
        "    print(\"\\\\nkmeans_10_clusters distribution:\")\n",
        "    print(adata.obs['kmeans_10_clusters'].value_counts())\n",
        "    ```\n",
        "\n",
        "    Q: \"Calculate correlation between the top 3 most highly expressed genes\"\n",
        "    A: ```python\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from scipy import sparse\n",
        "\n",
        "    # Calculate mean expression for each gene\n",
        "    if sparse.issparse(adata.X):\n",
        "        mean_expr = np.array(adata.X.mean(axis=0)).flatten()\n",
        "    else:\n",
        "        mean_expr = np.mean(adata.X, axis=0)\n",
        "\n",
        "    # Get top 3 genes\n",
        "    top_genes_idx = np.argsort(mean_expr)[-3:]\n",
        "    top_genes = adata.var_names[top_genes_idx]\n",
        "\n",
        "    # Extract expression data for top genes\n",
        "    expr_matrix = adata[:, top_genes].X\n",
        "    if sparse.issparse(expr_matrix):\n",
        "        expr_matrix = expr_matrix.toarray()\n",
        "\n",
        "    # Create correlation matrix\n",
        "    corr_df = pd.DataFrame(expr_matrix, columns=top_genes)\n",
        "    corr_matrix = corr_df.corr()\n",
        "\n",
        "    # Plot correlation heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(corr_matrix,\n",
        "                annot=True,\n",
        "                cmap='coolwarm',\n",
        "                vmin=-1,\n",
        "                vmax=1,\n",
        "                center=0)\n",
        "    plt.title('Correlation between top 3 highly expressed genes')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print mean expression values\n",
        "    print(\"\\\\nMean expression values:\")\n",
        "    for gene, mean_exp in zip(top_genes, mean_expr[top_genes_idx]):\n",
        "        print(f\"{{gene}}: {{mean_exp:.2f}}\")\n",
        "    ```\n",
        "\n",
        "    Question: What are the different ligand and receptor pairs in the TGFb pathway?\n",
        "    Answer:\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    df_ligrec=ct.pp.ligand_receptor_database(database='CellChat', species='human')\n",
        "    tgfb = df_ligrec[df_ligrec[2]=='TGFb']\n",
        "    tgfb\n",
        "    '''\n",
        "    Question: Perform cell-cell communication analysis for the TGFb pathway.\n",
        "    Only access the df_ligrec database with .iloc.\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    df_ligrec=ct.pp.ligand_receptor_database(database='CellChat', species='human')\n",
        "    tgfb = df_ligrec[df_ligrec.iloc[:,2]=='TGFb']\n",
        "    ct.tl.spatial_communication(adata,\n",
        "    database_name='cellchat', df_ligrec=tgfb, dis_thr=500, heteromeric=True, pathway_sum=True)\n",
        "\n",
        "    Question: Can you construct a cell-cell communication networks of the TGFb pathway between cells within 500 m?\n",
        "    Answer:\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    df_ligrec=ct.pp.ligand_receptor_database(database='CellChat', species='human')\n",
        "    tgfb = df_ligrec[df_ligrec.iloc[:,2]=='TGFb']\n",
        "    ct.tl.spatial_communication(adata,\n",
        "    database_name='cellchat', df_ligrec=tgfb, dis_thr=500, heteromeric=True, pathway_sum=True)\n",
        "    '''\n",
        "\n",
        "    Question: How do I visualize the amount of sent and received signal between SEMA3A and NRP1_PLXNA1?\n",
        "    Answer:\n",
        "    Here's how to plot the signaling levels for the SEMA3A-NRP1_PLXNA1 pair.\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    #define the LR pair\n",
        "    LR = np.array([['SEMA3A', 'NRP1_PLXNA2', 'SEMA3']], dtype=str)\n",
        "    LR = pd.DataFrame(data=LR)\n",
        "    ct.tl.spatial_communication(adata,\n",
        "    database_name='cellchat', df_ligrec=LR, dis_thr=500, heteromeric=True, pathway_sum=True)\n",
        "    pts = adata.obsm['spatial']\n",
        "    s = adata.obsm['commot-cellchat-sum-sender']['s-SEMA3A']\n",
        "    r = adata.obsm['commot-cellchat-sum-receiver']['r-NRP1-PLXNA2']\n",
        "    fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "    ax[0].scatter(pts[:,0], pts[:,1], c=s, s=5, cmap='Blues')\n",
        "    ax[0].set_title('Sender')\n",
        "    ax[1].scatter(pts[:,0], pts[:,1], c=r, s=5, cmap='Reds')\n",
        "    ax[1].set_title('Receiver')\n",
        "    '''\n",
        "\n",
        "    Question: How can I visualize signaling directions for TGFB1-TGFBR1_TGFBR2 as vector fields?\n",
        "    Answer:\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    ct.tl.communication_direction(adata, database_name='cellchat', lr_pair=('TGFB1','TGFBR1_TGFBR2'), k=5)\n",
        "    ct.pl.plot_cell_communication(adata, database_name='cellchat', lr_pair=('TGFB1','TGFBR1_TGFBR2'), plot_method='grid', background_legend=True,\n",
        "    scale=0.00003, ndsize=8, grid_density=0.4, summary='sender', background='image', clustering='leiden', cmap='Alphabet',\n",
        "    normalize_v = True, normalize_v_quantile=0.995)\n",
        "    '''\n",
        "\n",
        "    Question: Can you show me the cell-cell interaction between TGFB1 and TGFBR1_TGFBR2?\n",
        "    Answer:\n",
        "    '''\n",
        "    import commot as ct\n",
        "    import scanpy as sc\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    ct.tl.communication_direction(adata, database_name='cellchat', lr_pair=('TGFB1','TGFBR1_TGFBR2'), k=5)\n",
        "    ct.pl.plot_cell_communication(adata, database_name='cellchat', lr_pair=('TGFB1','TGFBR1_TGFBR2'), plot_method='grid', background_legend=True,\n",
        "    scale=0.00003, ndsize=8, grid_density=0.4, summary='receiver', background='summary', clustering='leiden', cmap='Reds',\n",
        "    normalize_v = True, normalize_v_quantile=0.995)\n",
        "    '''\n",
        "\n",
        "    Current question to analyze: {question}\n",
        "\n",
        "    First, analyze the type of operation requested and then provide the appropriate code or response.\n",
        "    \"\"\"\n",
        "\n",
        "    vertexai.init(project=\"isb-cgc-external-004\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-flash-002\",\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "        # tools='code_execution'\n",
        "    )\n",
        "\n",
        "\n",
        "    pattern = r'```python\\n(.*?)\\n```'\n",
        "    match = re.search(pattern, responses.text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        python_code = match.group(1).strip()\n",
        "        print(\"Generated code:\", python_code)\n",
        "\n",
        "        # Dictionary to capture local variables from exec\n",
        "        local_vars = {}\n",
        "\n",
        "        # Execute the code in the local_vars dictionary to capture output\n",
        "        exec(python_code, globals(), local_vars)\n",
        "\n",
        "        # Update the global scope with new variables\n",
        "        globals().update(local_vars)\n",
        "\n",
        "        print(\"Agent 2: Executed Python code with accessible variables.\")\n",
        "    else:\n",
        "        print(responses.text)\n",
        "        print(\"Agent 2: No executable code found.\")\n",
        "\n",
        "toolkit = [agent_1, agent_2]\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def agent_3(question:str) -> str:\n",
        "    \"\"\"\n",
        "    Given output of a tool calling agent, convert the output to a human readable format.\n",
        "\n",
        "    Parameters:\n",
        "    question (str): Raw outputs from the tool calling agent.\n",
        "\n",
        "    Returns:\n",
        "    str: Human readable version of the raw output string.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = \"\"\"You are an experienced writer and editor. When given an input, convert it into a well formatted string output. If the input string is blank, just say that there are no outputs generated for the current query.\n",
        "\n",
        "    Here are some examples:\n",
        "    Example 1:\n",
        "    Input: '''\n",
        "    Generated code: import scanpy as sc\n",
        "    import pandas as pd\n",
        "\n",
        "    adata = sc.read_h5ad(\"/content/demo_data/6723_KL_1_unfiltered.h5ad\")\n",
        "    print(adata)\n",
        "    AnnData object with n_obs  n_vars = 4992  19074\n",
        "    obs: 'in_tissue', 'array_row', 'array_col', 'kmeans_7_clusters', 'kmeans_10_clusters', 'kmeans_4_clusters', 'kmeans_2_clusters', 'kmeans_6_clusters', 'graphclust', 'kmeans_3_clusters', 'kmeans_8_clusters', 'kmeans_9_clusters', 'kmeans_5_clusters'\n",
        "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells', 'Morans_I', 'Morans_I_p_val', 'Morans_I_adj_p_val', 'Feature Counts in Spots Under Tissue', 'Median Normalized Average Counts', 'Barcodes Detected per Feature'\n",
        "    uns: 'spatial'\n",
        "    obsm: 'spatial'\n",
        "    Agent 2: Executed Python code with accessible variables.\n",
        "    The agent action is tool='agent_2' tool_input={'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'} log=\"\\nInvoking: `agent_2` with `{'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_2', 'arguments': '{\"question\": \"Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 380, 'candidates_token_count': 35, 'total_token_count': 415, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.004535583513123649, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-7d91d738-3af2-468a-bb2b-e9b23235e38a-0', tool_calls=[{'name': 'agent_2', 'args': {'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'}, 'id': '62e66320-2760-4403-9049-43fd7a676e0f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 380, 'output_tokens': 35, 'total_tokens': 415})] tool_call_id='62e66320-2760-4403-9049-43fd7a676e0f'\n",
        "    The tool result is: None\n",
        "    {'intermediate_steps': [(ToolAgentAction(tool='agent_2', tool_input={'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'}, log=\"\\nInvoking: `agent_2` with `{'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_2', 'arguments': '{\"question\": \"Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 380, 'candidates_token_count': 35, 'total_token_count': 415, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.004535583513123649, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-7d91d738-3af2-468a-bb2b-e9b23235e38a-0', tool_calls=[{'name': 'agent_2', 'args': {'question': 'Can you use scanpy to load the /content/demo_data/6723_KL_1_unfiltered.h5ad?'}, 'id': '62e66320-2760-4403-9049-43fd7a676e0f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 380, 'output_tokens': 35, 'total_tokens': 415})], tool_call_id='62e66320-2760-4403-9049-43fd7a676e0f'), 'None')]}\n",
        "\n",
        "    '''\n",
        "    Well formated output:\n",
        "\n",
        "    '''The dataset is loaded to the anndata object named adata. There are 4992 cells or spots, 19074 genes, and 13 feature columns. The data object is printed below:\n",
        "\n",
        "    AnnData object with n_obs  n_vars = 4992  19074\n",
        "    obs: 'in_tissue', 'array_row', 'array_col', 'kmeans_7_clusters', 'kmeans_10_clusters', 'kmeans_4_clusters', 'kmeans_2_clusters', 'kmeans_6_clusters', 'graphclust', 'kmeans_3_clusters', 'kmeans_8_clusters', 'kmeans_9_clusters', 'kmeans_5_clusters'\n",
        "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells', 'Morans_I', 'Morans_I_p_val', 'Morans_I_adj_p_val', 'Feature Counts in Spots Under Tissue', 'Median Normalized Average Counts', 'Barcodes Detected per Feature'\n",
        "    uns: 'spatial'\n",
        "    obsm: 'spatial'\n",
        "    '''\n",
        "\n",
        "    Example 2:\n",
        "    Input: '''\n",
        "    Welcome, arun.das!\n",
        "\n",
        "    INFO:synapseclient_default:Welcome, arun.das!\n",
        "\n",
        "    Downloading files:  77%|  | 16.8M/21.8M [00:00<00:00, 28.0MB/s, syn51133599]Downloaded syn51133599 to /content/demo_data/8578_AS_1_unfiltered.h5ad\n",
        "    [INFO] Downloaded syn51133599 to /content/demo_data/8578_AS_1_unfiltered.h5ad\n",
        "    Downloading files: 100%|| 21.8M/21.8M [00:00<00:00, 31.8MB/s, syn51133599]INFO:synapseclient_default:Downloaded syn51133599 to /content/demo_data/8578_AS_1_unfiltered.h5ad\n",
        "    Downloading files: 100%|| 21.8M/21.8M [00:00<00:00, 31.6MB/s, syn51133599]import synapseclient\n",
        "    syn = synapseclient.login(silent=True)\n",
        "    entity = syn.get('syn51133599', downloadLocation='/content/demo_data')\n",
        "    The agent action is tool='agent_1' tool_input={'question': 'Can you download the synapse dataset syn51133599 to /content/demo_data/?'} log=\"\\nInvoking: `agent_1` with `{'question': 'Can you download the synapse dataset syn51133599 to /content/demo_data/?'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_1', 'arguments': '{\"question\": \"Can you download the synapse dataset syn51133599 to /content/demo_data/?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 396, 'candidates_token_count': 27, 'total_token_count': 423, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0003545089038433852, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-49c29b88-a638-4a7d-89fa-122d8edb910d-0', tool_calls=[{'name': 'agent_1', 'args': {'question': 'Can you download the synapse dataset syn51133599 to /content/demo_data/?'}, 'id': '48d647d4-94d2-4cae-bd6f-f5d5e2240945', 'type': 'tool_call'}], usage_metadata={'input_tokens': 396, 'output_tokens': 27, 'total_tokens': 423})] tool_call_id='48d647d4-94d2-4cae-bd6f-f5d5e2240945'\n",
        "    The tool result is: None\n",
        "    ----\n",
        "    '''\n",
        "\n",
        "    Well formated output:\n",
        "    '''\n",
        "    The synapse dataset with synapse id syn51133599 is successfully downloaded to /content/demo_data/8578_AS_1_unfiltered.h5ad.\n",
        "    '''\n",
        "\n",
        "\n",
        "    Example 3:\n",
        "    Input: '''\n",
        "    {'agent_outcome': [ToolAgentAction(tool='agent_1', tool_input={'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}, log=\"\\nInvoking: `agent_1` with `{'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_1', 'arguments': '{\"question\": \"Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 536, 'candidates_token_count': 49, 'total_token_count': 585, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0002904396352111077, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-b2cf906b-d897-4164-b743-1120419ebdf9-0', tool_calls=[{'name': 'agent_1', 'args': {'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}, 'id': '6987b536-4024-4b91-a0b1-720e41b1076e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 536, 'output_tokens': 49, 'total_tokens': 585})], tool_call_id='6987b536-4024-4b91-a0b1-720e41b1076e')]}\n",
        "    import pandas_gbq\n",
        "    from google.cloud import bigquery\n",
        "    import synapseclient\n",
        "\n",
        "    project_id = \"isb-cgc-external-004\"\n",
        "\n",
        "    query = '''\n",
        "    SELECT entityId\n",
        "    FROM `isb-cgc-bq.HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current`\n",
        "    WHERE File_Format = 'hdf5'\n",
        "    '''\n",
        "\n",
        "    df = pandas_gbq.read_gbq(query, project_id=project_id)\n",
        "    print(df)\n",
        "\n",
        "    syn = synapseclient.login(silent=True)\n",
        "    entity = syn.get('syn51133602', downloadLocation='/content/datasets')\n",
        "    Downloading: 100%|##########|\n",
        "        entityId\n",
        "    0   syn51133519\n",
        "    1   syn51133520\n",
        "    2   syn51133521\n",
        "    3   syn51133522\n",
        "    4   syn51133523\n",
        "    5   syn51133524\n",
        "    6   syn51133525\n",
        "    7   syn51133526\n",
        "    8   syn51133527\n",
        "    9   syn51133528\n",
        "    10  syn51133529\n",
        "    11  syn51133530\n",
        "    12  syn51133531\n",
        "    13  syn51133532\n",
        "    14  syn51133533\n",
        "    15  syn51133534\n",
        "    16  syn51133537\n",
        "    17  syn51133540\n",
        "    18  syn51133578\n",
        "    19  syn51133580\n",
        "    20  syn51133583\n",
        "    21  syn51133587\n",
        "    22  syn51133591\n",
        "    23  syn51133592\n",
        "    24  syn51133593\n",
        "    25  syn51133595\n",
        "    26  syn51133596\n",
        "    27  syn51133597\n",
        "    28  syn51133598\n",
        "    29  syn51133599\n",
        "    30  syn51133600\n",
        "    31  syn51133601\n",
        "    32  syn51133602\n",
        "    33  syn51133603\n",
        "    34  syn51133604\n",
        "    35  syn51133605\n",
        "    36  syn51133606\n",
        "    37  syn51133607\n",
        "    38  syn51133608\n",
        "    39  syn51133609\n",
        "    40  syn51133612\n",
        "    The agent action is tool='agent_1' tool_input={'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'} log=\"\\nInvoking: `agent_1` with `{'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_1', 'arguments': '{\"question\": \"Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 536, 'candidates_token_count': 49, 'total_token_count': 585, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0002904396352111077, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-b2cf906b-d897-4164-b743-1120419ebdf9-0', tool_calls=[{'name': 'agent_1', 'args': {'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}, 'id': '6987b536-4024-4b91-a0b1-720e41b1076e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 536, 'output_tokens': 49, 'total_tokens': 585})] tool_call_id='6987b536-4024-4b91-a0b1-720e41b1076e'\n",
        "    The tool result is: None\n",
        "    {'intermediate_steps': [(ToolAgentAction(tool='agent_1', tool_input={'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}, log=\"\\nInvoking: `agent_1` with `{'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'agent_1', 'arguments': '{\"question\": \"Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 536, 'candidates_token_count': 49, 'total_token_count': 585, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0002904396352111077, 'logprobs_result': {'top_candidates': [], 'chosen_candidates': []}}, id='run-b2cf906b-d897-4164-b743-1120419ebdf9-0', tool_calls=[{'name': 'agent_1', 'args': {'question': 'Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?'}, 'id': '6987b536-4024-4b91-a0b1-720e41b1076e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 536, 'output_tokens': 49, 'total_tokens': 585})], tool_call_id='6987b536-4024-4b91-a0b1-720e41b1076e'), 'None')]}\n",
        "    ---- Initial response captured ----\n",
        "    '''\n",
        "    Well formatted output:\n",
        "    '''\n",
        "    A total of 41 entity IDs were retrieved from the BigQuery table isb-cgc-bq.HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is 'hdf5'.  The entity IDs are listed below::\n",
        "\n",
        "    1. syn51133519\n",
        "    2. syn51133520\n",
        "    3. syn51133521\n",
        "    4. syn51133522\n",
        "    5. syn51133523\n",
        "    6. syn51133524\n",
        "    7. syn51133525\n",
        "    8. syn51133526\n",
        "    9. syn51133527\n",
        "    10. syn51133528\n",
        "    11. syn51133529\n",
        "    12. syn51133530\n",
        "    13. syn51133531\n",
        "    14. syn51133532\n",
        "    15. syn51133533\n",
        "    16. syn51133534\n",
        "    17. syn51133537\n",
        "    18. syn51133540\n",
        "    19. syn51133578\n",
        "    20. syn51133580\n",
        "    21. syn51133583\n",
        "    22. syn51133587\n",
        "    23. syn51133591\n",
        "    24. syn51133592\n",
        "    25. syn51133593\n",
        "    26. syn51133595\n",
        "    27. syn51133596\n",
        "    28. syn51133597\n",
        "    29. syn51133598\n",
        "    30. syn51133599\n",
        "    31. syn51133600\n",
        "    32. syn51133601\n",
        "    33. syn51133602\n",
        "    34. syn51133603\n",
        "    35. syn51133604\n",
        "    36. syn51133605\n",
        "    37. syn51133606\n",
        "    38. syn51133607\n",
        "    39. syn51133608\n",
        "    40. syn51133609\n",
        "    41. syn51133612\n",
        "    '''\n",
        "    \"\"\"\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Input: {question}\n",
        "    Please generate the well formated output.\n",
        "    \"\"\"\n",
        "\n",
        "    vertexai.init(project=\"isb-cgc-external-004\", location=\"us-central1\")\n",
        "    model = GenerativeModel(\n",
        "        \"gemini-1.5-flash-002\",\n",
        "    )\n",
        "    responses = model.generate_content(\n",
        "        [prompt],\n",
        "        generation_config=generation_config,\n",
        "        safety_settings=safety_settings,\n",
        "        stream=False,\n",
        "        # tools='code_execution'\n",
        "    )\n",
        "\n",
        "    # Example usage\n",
        "    display(Markdown(responses.text))\n",
        "\n",
        "llm = ChatVertexAI(model_name= 'gemini-1.5-flash-002')\n",
        "#define system prompt for tool calling agent\n",
        "system_prompt = \"\"\"\n",
        "You are a supervisor who can select the right worker to complete a task. The workers are called agents, and we have two agents, agent_1 and agent_2, each skilled in specific tasks, as described below:\n",
        "\n",
        "- Use `agent_1` to generate code for downloading files from Synapse or the HTAN database. If the user request involves data retrieval from an external source like Synapse, agent_1 is the correct choice.\n",
        "\n",
        "- Use `agent_2` to generate code for handling tasks related to the AnnData object, named `adata`, which is available in the local variables. Specifically:\n",
        "  - Select `agent_2` for tasks that involve loading, preprocessing, or analyzing the `adata` object.\n",
        "  - Use `agent_2` when the users question requires performing operations on `adata`, such as filtering, normalization, dimensionality reduction, or any other preprocessing step.\n",
        "  - For questions or analysis based on the data contained within `adata`, also use `agent_2`.\n",
        "\n",
        "If you do not have a tool to answer the question, inform the user accordingly.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "tool_calling_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "tool_runnable = create_tool_calling_agent(llm, toolkit, prompt  = tool_calling_prompt)\n",
        "\n",
        "\n",
        "def run_tool_agent(state):\n",
        "    agent_outcome = tool_runnable.invoke(state)\n",
        "\n",
        "    #this agent will overwrite the agent outcome state variable\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "# tool executor invokes the tool action specified from the agent runnable\n",
        "# they will become the nodes that will be called when the agent decides on a tool action.\n",
        "\n",
        "tool_executor = ToolExecutor(toolkit)\n",
        "\n",
        "# Define the function to execute tools\n",
        "# This node will run a different tool as specified in the state variable agent_outcome\n",
        "def execute_tools(state):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_action = state['agent_outcome']\n",
        "    if type(agent_action) is not list:\n",
        "        agent_action = [agent_action]\n",
        "    steps = []\n",
        "    #sca only returns an action while tool calling returns a list\n",
        "    # convert single actions to a list\n",
        "\n",
        "    for action in agent_action:\n",
        "    # Execute the tool\n",
        "        output = tool_executor.invoke(action)\n",
        "        print(f\"The agent action is {action}\")\n",
        "        print(f\"The tool result is: {output}\")\n",
        "        steps.append((action, str(output)))\n",
        "    # Return the output\n",
        "    return {\"intermediate_steps\": steps}\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "   # The input string from human\n",
        "   input: str\n",
        "   # The list of previous messages in the conversation\n",
        "   chat_history: list[BaseMessage]\n",
        "   # The outcome of a given call to the agent\n",
        "   # Needs 'list' as a valid type as the tool agent returns a list.\n",
        "   # Needs `None` as a valid type, since this is what this will start as\n",
        "   # this state will be overwritten with the latest everytime the agent is run\n",
        "   agent_outcome: Union[AgentAction, list, ToolAgentAction, AgentFinish, None]\n",
        "\n",
        "   # List of actions and corresponding observations\n",
        "   # These actions should be added onto the existing so we use `operator.add`\n",
        "   # to append to the list of past intermediate steps\n",
        "   intermediate_steps: Annotated[list[Union[tuple[AgentAction, str], tuple[ToolAgentAction, str]]], operator.add]\n",
        "\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if isinstance(data['agent_outcome'], AgentFinish):\n",
        "        return \"END\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        return \"CONTINUE\"\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# When nodes are called, the functions for to the tools will be called.\n",
        "workflow.add_node(\"agent\", run_tool_agent)\n",
        "\n",
        "\n",
        "# Add tool invocation node to the graph\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "\n",
        "# Define which node the graph will invoke at start.\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# Add flow logic with static edge.\n",
        "# Each time a tool is invoked and completed we want to\n",
        "# return the result to the agent to assess if task is complete or to take further actions\n",
        "\n",
        "#each action invocation has an edge leading to the agent node.\n",
        "workflow.add_edge('action', 'agent')\n",
        "\n",
        "\n",
        "# Add flow logic with conditional edge.\n",
        "workflow.add_conditional_edges(\n",
        "    # first parameter is the starting node for the edge\n",
        "    \"agent\",\n",
        "    # the second parameter specifies the logic function to be run\n",
        "    # to determine which node the edge will point to given the state.\n",
        "    should_continue,\n",
        "\n",
        "    #third parameter defines the mapping between the logic function\n",
        "    #output and the nodes on the graph\n",
        "    # For each possible output of the logic function there must be a valid node.\n",
        "    {\n",
        "        # If 'continue' we proceed to the action node.\n",
        "        \"CONTINUE\": \"action\",\n",
        "        # Otherwise we end invocations with the END node.\n",
        "        \"END\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Finally, compile the graph!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "app = workflow.compile(checkpointer = memory)\n",
        "\n",
        "def ask_agents(user_question, config={\"configurable\": {\"thread_id\": \"1\"}}):\n",
        "    \"\"\"\n",
        "    Executes an application stream with enhanced error handling and logs the output.\n",
        "\n",
        "    Parameters:\n",
        "    - user_question: A string representing the user's question or command.\n",
        "    - config: A dictionary with configuration settings for the app, such as 'thread_id'.\n",
        "\n",
        "    Returns:\n",
        "    - The captured standard output as a string.\n",
        "    \"\"\"\n",
        "    buffer = io.StringIO()  # Capture output buffer\n",
        "    inputs = {\"input\": user_question, \"chat_history\": []}  # Set up inputs for the stream\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")  # Ignore warnings during execution\n",
        "        # Redirect stdout to the buffer to capture printed output\n",
        "        with redirect_stdout(buffer):\n",
        "            try:\n",
        "                # Stream output and capture responses\n",
        "                for i, response_chunk in enumerate(app.stream(inputs, config=config)):\n",
        "                    result = list(response_chunk.values())[0]  # Accessing the actual response content\n",
        "                    print(result)  # Print result to buffer to capture it\n",
        "                    if i == 1:\n",
        "                        # Optionally break after the initial response\n",
        "                        print(\"---- Initial response captured ----\")\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                # Print the error in the captured output\n",
        "                print(f\"Error during streaming execution: {e}\")\n",
        "\n",
        "    # Retrieve the contents of the buffer as a string\n",
        "    return buffer.getvalue()\n",
        "\n",
        "# Example usage to show HTAN data browsing\n",
        "user_question = \"Can you load the entityId of all data under HTAN.10xvisium_spatialtranscriptomics_scRNAseq_level4_metadata_current where the File_Format is hdf5?\"\n",
        "\n",
        "# Example usage to show HTAN data browsing\n",
        "# user_question = \"Can you download the Synapse datasaet with id syn51133612 to /content/demo_data/?\"\n",
        "\n",
        "# user_question = \"Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\"\n",
        "\n",
        "# user_question = \"Please preprocess the adata object\"\n",
        "\n",
        "# user_question = \"Generate a UMAP visualization comparing kmeans_9_clusters with kmeans_10_clusters\"\n",
        "\n",
        "output = ask_agents(user_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OIV9zuYQ-NCN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1731090744631,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "OIV9zuYQ-NCN",
        "outputId": "391b107d-745f-460a-89d1-e7e858331c38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\'agent_outcome\\': [ToolAgentAction(tool=\\'agent_2\\', tool_input={\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}, log=\"\\\\nInvoking: `agent_2` with `{\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}`\\\\n\\\\n\\\\n\", message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'agent_2\\', \\'arguments\\': \\'{\"question\": \"Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\"}\\'}}, response_metadata={\\'is_blocked\\': False, \\'safety_ratings\\': [], \\'usage_metadata\\': {\\'prompt_token_count\\': 524, \\'candidates_token_count\\': 37, \\'total_token_count\\': 561, \\'cached_content_token_count\\': 0}, \\'finish_reason\\': \\'STOP\\', \\'avg_logprobs\\': -0.03173088705217516, \\'logprobs_result\\': {\\'top_candidates\\': [], \\'chosen_candidates\\': []}}, id=\\'run-0fe65e7f-1452-4d60-8c6d-e9452bf2ae02-0\\', tool_calls=[{\\'name\\': \\'agent_2\\', \\'args\\': {\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}, \\'id\\': \\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\', \\'type\\': \\'tool_call\\'}], usage_metadata={\\'input_tokens\\': 524, \\'output_tokens\\': 37, \\'total_tokens\\': 561})], tool_call_id=\\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\')]}\\nGenerated code: import scanpy as sc\\nimport anndata as ad\\nimport os\\n\\n# Check if the file exists\\nfilepath = \"/content/demo_data/8899_AS_8_unfiltered.h5ad\"\\nif not os.path.exists(filepath):\\n    raise FileNotFoundError(f\"Error: File not found at {filepath}\")\\n\\ntry:\\n    # Load the .h5ad file into an AnnData object\\n    adata = sc.read_h5ad(filepath)\\n    print(f\"Successfully loaded {filepath} into adata.\")\\n    print(adata) # Print adata information to verify loading\\n\\nexcept Exception as e:\\n    print(f\"An error occurred while loading the file: {e}\")\\nSuccessfully loaded /content/demo_data/8899_AS_8_unfiltered.h5ad into adata.\\nAnnData object with n_obs  n_vars = 4992  18729\\n    obs: \\'in_tissue\\', \\'array_row\\', \\'array_col\\', \\'kmeans_7_clusters\\', \\'kmeans_10_clusters\\', \\'kmeans_4_clusters\\', \\'kmeans_2_clusters\\', \\'kmeans_6_clusters\\', \\'graphclust\\', \\'kmeans_3_clusters\\', \\'kmeans_8_clusters\\', \\'kmeans_9_clusters\\', \\'kmeans_5_clusters\\'\\n    var: \\'gene_ids\\', \\'feature_types\\', \\'genome\\', \\'n_cells\\', \\'Morans_I\\', \\'Morans_I_p_val\\', \\'Morans_I_adj_p_val\\', \\'Feature Counts in Spots Under Tissue\\', \\'Median Normalized Average Counts\\', \\'Barcodes Detected per Feature\\'\\n    uns: \\'spatial\\'\\n    obsm: \\'spatial\\'\\nAgent 2: Executed Python code with accessible variables.\\nThe agent action is tool=\\'agent_2\\' tool_input={\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'} log=\"\\\\nInvoking: `agent_2` with `{\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}`\\\\n\\\\n\\\\n\" message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'agent_2\\', \\'arguments\\': \\'{\"question\": \"Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\"}\\'}}, response_metadata={\\'is_blocked\\': False, \\'safety_ratings\\': [], \\'usage_metadata\\': {\\'prompt_token_count\\': 524, \\'candidates_token_count\\': 37, \\'total_token_count\\': 561, \\'cached_content_token_count\\': 0}, \\'finish_reason\\': \\'STOP\\', \\'avg_logprobs\\': -0.03173088705217516, \\'logprobs_result\\': {\\'top_candidates\\': [], \\'chosen_candidates\\': []}}, id=\\'run-0fe65e7f-1452-4d60-8c6d-e9452bf2ae02-0\\', tool_calls=[{\\'name\\': \\'agent_2\\', \\'args\\': {\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}, \\'id\\': \\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\', \\'type\\': \\'tool_call\\'}], usage_metadata={\\'input_tokens\\': 524, \\'output_tokens\\': 37, \\'total_tokens\\': 561})] tool_call_id=\\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\'\\nThe tool result is: None\\n{\\'intermediate_steps\\': [(ToolAgentAction(tool=\\'agent_2\\', tool_input={\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}, log=\"\\\\nInvoking: `agent_2` with `{\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}`\\\\n\\\\n\\\\n\", message_log=[AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'agent_2\\', \\'arguments\\': \\'{\"question\": \"Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\"}\\'}}, response_metadata={\\'is_blocked\\': False, \\'safety_ratings\\': [], \\'usage_metadata\\': {\\'prompt_token_count\\': 524, \\'candidates_token_count\\': 37, \\'total_token_count\\': 561, \\'cached_content_token_count\\': 0}, \\'finish_reason\\': \\'STOP\\', \\'avg_logprobs\\': -0.03173088705217516, \\'logprobs_result\\': {\\'top_candidates\\': [], \\'chosen_candidates\\': []}}, id=\\'run-0fe65e7f-1452-4d60-8c6d-e9452bf2ae02-0\\', tool_calls=[{\\'name\\': \\'agent_2\\', \\'args\\': {\\'question\\': \\'Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\\'}, \\'id\\': \\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\', \\'type\\': \\'tool_call\\'}], usage_metadata={\\'input_tokens\\': 524, \\'output_tokens\\': 37, \\'total_tokens\\': 561})], tool_call_id=\\'64ab7d79-31b2-4409-9e45-523e0adec0a8\\'), \\'None\\')]}\\n---- Initial response captured ----\\n'"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_question = \"Can you load the /content/demo_data/8899_AS_8_unfiltered.h5ad to adata using scanpy?\"\n",
        "output = ask_agents(user_question)\n",
        "pritn(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vN-I7p8epfmP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "executionInfo": {
          "elapsed": 2162,
          "status": "ok",
          "timestamp": 1731090748832,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "vN-I7p8epfmP",
        "outputId": "d81c50f9-9dcd-401f-ee4d-43e60a146927"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "```\n",
              "The file `/content/demo_data/8899_AS_8_unfiltered.h5ad` was successfully loaded into the `adata` AnnData object using scanpy.  The object contains information for 4992 observations (cells or spots) and 18729 variables (genes).  Details are shown below:\n",
              "\n",
              "AnnData object with n_obs  n_vars = 4992  18729\n",
              "    obs: 'in_tissue', 'array_row', 'array_col', 'kmeans_7_clusters', 'kmeans_10_clusters', 'kmeans_4_clusters', 'kmeans_2_clusters', 'kmeans_6_clusters', 'graphclust', 'kmeans_3_clusters', 'kmeans_8_clusters', 'kmeans_9_clusters', 'kmeans_5_clusters'\n",
              "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells', 'Morans_I', 'Morans_I_p_val', 'Morans_I_adj_p_val', 'Feature Counts in Spots Under Tissue', 'Median Normalized Average Counts', 'Barcodes Detected per Feature'\n",
              "    uns: 'spatial'\n",
              "    obsm: 'spatial'\n",
              "```\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agent_3(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LMAREIDSmxFd",
      "metadata": {
        "id": "LMAREIDSmxFd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rA3onWxe-23B",
      "metadata": {
        "id": "rA3onWxe-23B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-L-k7KgZ-2wo",
      "metadata": {
        "id": "-L-k7KgZ-2wo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EUBE3Y-B-2oO",
      "metadata": {
        "id": "EUBE3Y-B-2oO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "app_v2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "crawl4ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
